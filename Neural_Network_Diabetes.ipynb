{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOw/yk3XztorV54zIsV52Uf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oviedof1/Machine-Learning/blob/master/Neural_Network_Diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-_miHlj_q5T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1aaff08b-1780-4f7f-858a-3158ddc9eb63"
      },
      "source": [
        "#Description: Detects if a person has diabetes or not\n",
        "\n",
        "#Load libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fju-HeR8AUNN",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "0c025ad8-b39d-44da-fb19-fa88b969b7df"
      },
      "source": [
        "#load data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6f58b6b2-c635-4c91-8b6d-9ebd55f67428\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-6f58b6b2-c635-4c91-8b6d-9ebd55f67428\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving diabetes.csv to diabetes.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFY0fk5qAyzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "118eded5-0fb3-4cf2-cf63-6ba52cebf9c9"
      },
      "source": [
        "#store data\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "df.head(7)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "5            5      116             74  ...                     0.201   30        0\n",
              "6            3       78             50  ...                     0.248   26        1\n",
              "\n",
              "[7 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6iVtK5tA-a1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b186f305-1162-40b3-e5f1-dda9e6f8e703"
      },
      "source": [
        "#get shape of data\n",
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHrzuVuVBIDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "354720cf-78c8-4787-f15c-4ccbb4686089"
      },
      "source": [
        "#check for duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA_pfSS1BSjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "5548bc27-63d9-4089-b2b6-4e25de731172"
      },
      "source": [
        "#show number of missing data for each colum\n",
        "df.isnull().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub0dzDo2Belt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "e6d9a97e-c619-4416-ab86-c77f3549b179"
      },
      "source": [
        "#conver the data to numpy array\n",
        "dataset = df.values\n",
        "dataset"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El5gFMo5BvvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get all rows from first 8 columns of dataset\n",
        "x = dataset[:,0:8]\n",
        "y = dataset[:,8]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4fVdiw3CPaj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "67a31cfd-0093-4e68-ec83-07d4f14721a9"
      },
      "source": [
        "#process data\n",
        "from sklearn import preprocessing\n",
        "min_max_scalar = preprocessing.MinMaxScaler()\n",
        "x_scale = min_max_scalar.fit_transform(x)\n",
        "x_scale"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA6HY-umDE-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the data into 80% train and 20% test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scale, y, test_size = 0.2, random_state = 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBexNgQXDaND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build the model\n",
        "\n",
        "model = Sequential([\n",
        "                    Dense(12, activation='relu',input_shape=(8,)), \n",
        "                    Dense(15, activation='relu'), \n",
        "                    Dense(1, activation='sigmoid')\n",
        "                    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cht5j3iHHElQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile the model\n",
        "model.compile(optimizer='sgd', loss = 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxR81rwOEJKK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3544e2f9-beea-484f-8365-bb3749c239f6"
      },
      "source": [
        "#train the model\n",
        "hist = model.fit(x_train, y_train, batch_size=57, epochs=1000, validation_split=0.2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 491 samples, validate on 123 samples\n",
            "Epoch 1/1000\n",
            "491/491 [==============================] - 0s 564us/step - loss: 0.6867 - accuracy: 0.6191 - val_loss: 0.6844 - val_accuracy: 0.6341\n",
            "Epoch 2/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6819 - accuracy: 0.6334 - val_loss: 0.6797 - val_accuracy: 0.6585\n",
            "Epoch 3/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6777 - accuracy: 0.6395 - val_loss: 0.6758 - val_accuracy: 0.6585\n",
            "Epoch 4/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6743 - accuracy: 0.6375 - val_loss: 0.6726 - val_accuracy: 0.6585\n",
            "Epoch 5/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6714 - accuracy: 0.6395 - val_loss: 0.6699 - val_accuracy: 0.6585\n",
            "Epoch 6/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6689 - accuracy: 0.6477 - val_loss: 0.6675 - val_accuracy: 0.6585\n",
            "Epoch 7/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6669 - accuracy: 0.6477 - val_loss: 0.6655 - val_accuracy: 0.6585\n",
            "Epoch 8/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6650 - accuracy: 0.6477 - val_loss: 0.6637 - val_accuracy: 0.6585\n",
            "Epoch 9/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6634 - accuracy: 0.6477 - val_loss: 0.6623 - val_accuracy: 0.6585\n",
            "Epoch 10/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6621 - accuracy: 0.6477 - val_loss: 0.6610 - val_accuracy: 0.6504\n",
            "Epoch 11/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6609 - accuracy: 0.6477 - val_loss: 0.6600 - val_accuracy: 0.6504\n",
            "Epoch 12/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6600 - accuracy: 0.6477 - val_loss: 0.6590 - val_accuracy: 0.6504\n",
            "Epoch 13/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6591 - accuracy: 0.6477 - val_loss: 0.6582 - val_accuracy: 0.6504\n",
            "Epoch 14/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6583 - accuracy: 0.6477 - val_loss: 0.6575 - val_accuracy: 0.6504\n",
            "Epoch 15/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6577 - accuracy: 0.6477 - val_loss: 0.6570 - val_accuracy: 0.6504\n",
            "Epoch 16/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6572 - accuracy: 0.6477 - val_loss: 0.6564 - val_accuracy: 0.6504\n",
            "Epoch 17/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6566 - accuracy: 0.6477 - val_loss: 0.6559 - val_accuracy: 0.6504\n",
            "Epoch 18/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6562 - accuracy: 0.6477 - val_loss: 0.6553 - val_accuracy: 0.6504\n",
            "Epoch 19/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6557 - accuracy: 0.6477 - val_loss: 0.6549 - val_accuracy: 0.6504\n",
            "Epoch 20/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6553 - accuracy: 0.6477 - val_loss: 0.6545 - val_accuracy: 0.6504\n",
            "Epoch 21/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6550 - accuracy: 0.6477 - val_loss: 0.6542 - val_accuracy: 0.6504\n",
            "Epoch 22/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6547 - accuracy: 0.6477 - val_loss: 0.6539 - val_accuracy: 0.6504\n",
            "Epoch 23/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6544 - accuracy: 0.6477 - val_loss: 0.6536 - val_accuracy: 0.6504\n",
            "Epoch 24/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6541 - accuracy: 0.6477 - val_loss: 0.6533 - val_accuracy: 0.6504\n",
            "Epoch 25/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6538 - accuracy: 0.6477 - val_loss: 0.6530 - val_accuracy: 0.6504\n",
            "Epoch 26/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6537 - accuracy: 0.6477 - val_loss: 0.6528 - val_accuracy: 0.6504\n",
            "Epoch 27/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6533 - accuracy: 0.6477 - val_loss: 0.6525 - val_accuracy: 0.6504\n",
            "Epoch 28/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6531 - accuracy: 0.6477 - val_loss: 0.6523 - val_accuracy: 0.6504\n",
            "Epoch 29/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6530 - accuracy: 0.6477 - val_loss: 0.6521 - val_accuracy: 0.6504\n",
            "Epoch 30/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6528 - accuracy: 0.6477 - val_loss: 0.6519 - val_accuracy: 0.6504\n",
            "Epoch 31/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6525 - accuracy: 0.6477 - val_loss: 0.6517 - val_accuracy: 0.6504\n",
            "Epoch 32/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6523 - accuracy: 0.6477 - val_loss: 0.6515 - val_accuracy: 0.6504\n",
            "Epoch 33/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6521 - accuracy: 0.6477 - val_loss: 0.6513 - val_accuracy: 0.6504\n",
            "Epoch 34/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6519 - accuracy: 0.6477 - val_loss: 0.6511 - val_accuracy: 0.6504\n",
            "Epoch 35/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6518 - accuracy: 0.6477 - val_loss: 0.6509 - val_accuracy: 0.6504\n",
            "Epoch 36/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6516 - accuracy: 0.6477 - val_loss: 0.6507 - val_accuracy: 0.6504\n",
            "Epoch 37/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6514 - accuracy: 0.6477 - val_loss: 0.6505 - val_accuracy: 0.6504\n",
            "Epoch 38/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6512 - accuracy: 0.6477 - val_loss: 0.6503 - val_accuracy: 0.6504\n",
            "Epoch 39/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6510 - accuracy: 0.6477 - val_loss: 0.6502 - val_accuracy: 0.6504\n",
            "Epoch 40/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6508 - accuracy: 0.6477 - val_loss: 0.6500 - val_accuracy: 0.6504\n",
            "Epoch 41/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6507 - accuracy: 0.6477 - val_loss: 0.6498 - val_accuracy: 0.6504\n",
            "Epoch 42/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6504 - accuracy: 0.6477 - val_loss: 0.6496 - val_accuracy: 0.6504\n",
            "Epoch 43/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6503 - accuracy: 0.6477 - val_loss: 0.6495 - val_accuracy: 0.6504\n",
            "Epoch 44/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6502 - accuracy: 0.6477 - val_loss: 0.6493 - val_accuracy: 0.6504\n",
            "Epoch 45/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6499 - accuracy: 0.6477 - val_loss: 0.6491 - val_accuracy: 0.6504\n",
            "Epoch 46/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6497 - accuracy: 0.6477 - val_loss: 0.6489 - val_accuracy: 0.6504\n",
            "Epoch 47/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6495 - accuracy: 0.6477 - val_loss: 0.6487 - val_accuracy: 0.6504\n",
            "Epoch 48/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6493 - accuracy: 0.6477 - val_loss: 0.6486 - val_accuracy: 0.6504\n",
            "Epoch 49/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6492 - accuracy: 0.6477 - val_loss: 0.6484 - val_accuracy: 0.6504\n",
            "Epoch 50/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6490 - accuracy: 0.6477 - val_loss: 0.6483 - val_accuracy: 0.6504\n",
            "Epoch 51/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.6489 - accuracy: 0.6477 - val_loss: 0.6481 - val_accuracy: 0.6504\n",
            "Epoch 52/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6486 - accuracy: 0.6477 - val_loss: 0.6480 - val_accuracy: 0.6504\n",
            "Epoch 53/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6484 - accuracy: 0.6477 - val_loss: 0.6478 - val_accuracy: 0.6504\n",
            "Epoch 54/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6482 - accuracy: 0.6477 - val_loss: 0.6476 - val_accuracy: 0.6504\n",
            "Epoch 55/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6481 - accuracy: 0.6477 - val_loss: 0.6475 - val_accuracy: 0.6504\n",
            "Epoch 56/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6479 - accuracy: 0.6477 - val_loss: 0.6473 - val_accuracy: 0.6504\n",
            "Epoch 57/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6478 - accuracy: 0.6477 - val_loss: 0.6471 - val_accuracy: 0.6504\n",
            "Epoch 58/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6476 - accuracy: 0.6477 - val_loss: 0.6470 - val_accuracy: 0.6504\n",
            "Epoch 59/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6474 - accuracy: 0.6477 - val_loss: 0.6469 - val_accuracy: 0.6504\n",
            "Epoch 60/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6473 - accuracy: 0.6477 - val_loss: 0.6467 - val_accuracy: 0.6504\n",
            "Epoch 61/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6471 - accuracy: 0.6477 - val_loss: 0.6466 - val_accuracy: 0.6504\n",
            "Epoch 62/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6469 - accuracy: 0.6477 - val_loss: 0.6464 - val_accuracy: 0.6504\n",
            "Epoch 63/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6467 - accuracy: 0.6477 - val_loss: 0.6462 - val_accuracy: 0.6504\n",
            "Epoch 64/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6466 - accuracy: 0.6477 - val_loss: 0.6461 - val_accuracy: 0.6504\n",
            "Epoch 65/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6464 - accuracy: 0.6477 - val_loss: 0.6459 - val_accuracy: 0.6504\n",
            "Epoch 66/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6462 - accuracy: 0.6477 - val_loss: 0.6458 - val_accuracy: 0.6504\n",
            "Epoch 67/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6460 - accuracy: 0.6477 - val_loss: 0.6457 - val_accuracy: 0.6504\n",
            "Epoch 68/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6458 - accuracy: 0.6477 - val_loss: 0.6455 - val_accuracy: 0.6504\n",
            "Epoch 69/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6456 - accuracy: 0.6477 - val_loss: 0.6454 - val_accuracy: 0.6504\n",
            "Epoch 70/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6455 - accuracy: 0.6477 - val_loss: 0.6452 - val_accuracy: 0.6504\n",
            "Epoch 71/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6453 - accuracy: 0.6477 - val_loss: 0.6451 - val_accuracy: 0.6504\n",
            "Epoch 72/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6451 - accuracy: 0.6477 - val_loss: 0.6449 - val_accuracy: 0.6504\n",
            "Epoch 73/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6450 - accuracy: 0.6477 - val_loss: 0.6448 - val_accuracy: 0.6504\n",
            "Epoch 74/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6448 - accuracy: 0.6477 - val_loss: 0.6446 - val_accuracy: 0.6504\n",
            "Epoch 75/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6446 - accuracy: 0.6477 - val_loss: 0.6445 - val_accuracy: 0.6504\n",
            "Epoch 76/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6445 - accuracy: 0.6477 - val_loss: 0.6443 - val_accuracy: 0.6504\n",
            "Epoch 77/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6443 - accuracy: 0.6477 - val_loss: 0.6441 - val_accuracy: 0.6504\n",
            "Epoch 78/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6441 - accuracy: 0.6477 - val_loss: 0.6440 - val_accuracy: 0.6504\n",
            "Epoch 79/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6439 - accuracy: 0.6477 - val_loss: 0.6438 - val_accuracy: 0.6504\n",
            "Epoch 80/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6438 - accuracy: 0.6477 - val_loss: 0.6437 - val_accuracy: 0.6504\n",
            "Epoch 81/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6437 - accuracy: 0.6477 - val_loss: 0.6435 - val_accuracy: 0.6504\n",
            "Epoch 82/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.6435 - accuracy: 0.6477 - val_loss: 0.6433 - val_accuracy: 0.6504\n",
            "Epoch 83/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6433 - accuracy: 0.6477 - val_loss: 0.6432 - val_accuracy: 0.6504\n",
            "Epoch 84/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6431 - accuracy: 0.6477 - val_loss: 0.6430 - val_accuracy: 0.6504\n",
            "Epoch 85/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6429 - accuracy: 0.6477 - val_loss: 0.6429 - val_accuracy: 0.6504\n",
            "Epoch 86/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6427 - accuracy: 0.6477 - val_loss: 0.6427 - val_accuracy: 0.6504\n",
            "Epoch 87/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6426 - accuracy: 0.6477 - val_loss: 0.6426 - val_accuracy: 0.6504\n",
            "Epoch 88/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6424 - accuracy: 0.6477 - val_loss: 0.6424 - val_accuracy: 0.6504\n",
            "Epoch 89/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6423 - accuracy: 0.6477 - val_loss: 0.6423 - val_accuracy: 0.6504\n",
            "Epoch 90/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6420 - accuracy: 0.6477 - val_loss: 0.6421 - val_accuracy: 0.6504\n",
            "Epoch 91/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6419 - accuracy: 0.6477 - val_loss: 0.6419 - val_accuracy: 0.6504\n",
            "Epoch 92/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6418 - accuracy: 0.6477 - val_loss: 0.6418 - val_accuracy: 0.6504\n",
            "Epoch 93/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6415 - accuracy: 0.6477 - val_loss: 0.6416 - val_accuracy: 0.6504\n",
            "Epoch 94/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6414 - accuracy: 0.6477 - val_loss: 0.6415 - val_accuracy: 0.6504\n",
            "Epoch 95/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6412 - accuracy: 0.6477 - val_loss: 0.6413 - val_accuracy: 0.6504\n",
            "Epoch 96/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6411 - accuracy: 0.6477 - val_loss: 0.6411 - val_accuracy: 0.6504\n",
            "Epoch 97/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6409 - accuracy: 0.6477 - val_loss: 0.6410 - val_accuracy: 0.6504\n",
            "Epoch 98/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6408 - accuracy: 0.6477 - val_loss: 0.6408 - val_accuracy: 0.6504\n",
            "Epoch 99/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6405 - accuracy: 0.6477 - val_loss: 0.6407 - val_accuracy: 0.6504\n",
            "Epoch 100/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.6403 - accuracy: 0.6477 - val_loss: 0.6405 - val_accuracy: 0.6504\n",
            "Epoch 101/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6402 - accuracy: 0.6477 - val_loss: 0.6404 - val_accuracy: 0.6504\n",
            "Epoch 102/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6401 - accuracy: 0.6477 - val_loss: 0.6402 - val_accuracy: 0.6504\n",
            "Epoch 103/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6399 - accuracy: 0.6477 - val_loss: 0.6401 - val_accuracy: 0.6504\n",
            "Epoch 104/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6397 - accuracy: 0.6477 - val_loss: 0.6399 - val_accuracy: 0.6504\n",
            "Epoch 105/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6395 - accuracy: 0.6477 - val_loss: 0.6398 - val_accuracy: 0.6504\n",
            "Epoch 106/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6393 - accuracy: 0.6477 - val_loss: 0.6396 - val_accuracy: 0.6504\n",
            "Epoch 107/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6393 - accuracy: 0.6477 - val_loss: 0.6395 - val_accuracy: 0.6504\n",
            "Epoch 108/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6390 - accuracy: 0.6477 - val_loss: 0.6393 - val_accuracy: 0.6504\n",
            "Epoch 109/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6388 - accuracy: 0.6477 - val_loss: 0.6392 - val_accuracy: 0.6504\n",
            "Epoch 110/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6387 - accuracy: 0.6477 - val_loss: 0.6390 - val_accuracy: 0.6504\n",
            "Epoch 111/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6384 - accuracy: 0.6477 - val_loss: 0.6388 - val_accuracy: 0.6504\n",
            "Epoch 112/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6383 - accuracy: 0.6477 - val_loss: 0.6387 - val_accuracy: 0.6504\n",
            "Epoch 113/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6381 - accuracy: 0.6477 - val_loss: 0.6385 - val_accuracy: 0.6504\n",
            "Epoch 114/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6379 - accuracy: 0.6477 - val_loss: 0.6384 - val_accuracy: 0.6504\n",
            "Epoch 115/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6376 - accuracy: 0.6477 - val_loss: 0.6382 - val_accuracy: 0.6504\n",
            "Epoch 116/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6375 - accuracy: 0.6477 - val_loss: 0.6380 - val_accuracy: 0.6504\n",
            "Epoch 117/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6372 - accuracy: 0.6477 - val_loss: 0.6379 - val_accuracy: 0.6504\n",
            "Epoch 118/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6371 - accuracy: 0.6477 - val_loss: 0.6377 - val_accuracy: 0.6504\n",
            "Epoch 119/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6369 - accuracy: 0.6477 - val_loss: 0.6375 - val_accuracy: 0.6504\n",
            "Epoch 120/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6367 - accuracy: 0.6477 - val_loss: 0.6373 - val_accuracy: 0.6504\n",
            "Epoch 121/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6365 - accuracy: 0.6477 - val_loss: 0.6372 - val_accuracy: 0.6504\n",
            "Epoch 122/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6363 - accuracy: 0.6477 - val_loss: 0.6370 - val_accuracy: 0.6504\n",
            "Epoch 123/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6361 - accuracy: 0.6477 - val_loss: 0.6368 - val_accuracy: 0.6504\n",
            "Epoch 124/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6360 - accuracy: 0.6477 - val_loss: 0.6366 - val_accuracy: 0.6504\n",
            "Epoch 125/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6357 - accuracy: 0.6477 - val_loss: 0.6364 - val_accuracy: 0.6504\n",
            "Epoch 126/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6356 - accuracy: 0.6477 - val_loss: 0.6363 - val_accuracy: 0.6504\n",
            "Epoch 127/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6353 - accuracy: 0.6477 - val_loss: 0.6361 - val_accuracy: 0.6504\n",
            "Epoch 128/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6352 - accuracy: 0.6477 - val_loss: 0.6359 - val_accuracy: 0.6504\n",
            "Epoch 129/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6349 - accuracy: 0.6477 - val_loss: 0.6357 - val_accuracy: 0.6504\n",
            "Epoch 130/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6347 - accuracy: 0.6477 - val_loss: 0.6355 - val_accuracy: 0.6504\n",
            "Epoch 131/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6346 - accuracy: 0.6477 - val_loss: 0.6354 - val_accuracy: 0.6504\n",
            "Epoch 132/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6343 - accuracy: 0.6477 - val_loss: 0.6352 - val_accuracy: 0.6504\n",
            "Epoch 133/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6340 - accuracy: 0.6477 - val_loss: 0.6350 - val_accuracy: 0.6504\n",
            "Epoch 134/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6339 - accuracy: 0.6477 - val_loss: 0.6348 - val_accuracy: 0.6504\n",
            "Epoch 135/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6337 - accuracy: 0.6477 - val_loss: 0.6346 - val_accuracy: 0.6504\n",
            "Epoch 136/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6335 - accuracy: 0.6477 - val_loss: 0.6344 - val_accuracy: 0.6504\n",
            "Epoch 137/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6332 - accuracy: 0.6477 - val_loss: 0.6342 - val_accuracy: 0.6504\n",
            "Epoch 138/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6330 - accuracy: 0.6477 - val_loss: 0.6340 - val_accuracy: 0.6504\n",
            "Epoch 139/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6329 - accuracy: 0.6477 - val_loss: 0.6338 - val_accuracy: 0.6504\n",
            "Epoch 140/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6326 - accuracy: 0.6477 - val_loss: 0.6336 - val_accuracy: 0.6504\n",
            "Epoch 141/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6323 - accuracy: 0.6477 - val_loss: 0.6334 - val_accuracy: 0.6504\n",
            "Epoch 142/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6321 - accuracy: 0.6477 - val_loss: 0.6332 - val_accuracy: 0.6504\n",
            "Epoch 143/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6318 - accuracy: 0.6477 - val_loss: 0.6330 - val_accuracy: 0.6504\n",
            "Epoch 144/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6316 - accuracy: 0.6477 - val_loss: 0.6328 - val_accuracy: 0.6504\n",
            "Epoch 145/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6313 - accuracy: 0.6477 - val_loss: 0.6326 - val_accuracy: 0.6504\n",
            "Epoch 146/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6311 - accuracy: 0.6477 - val_loss: 0.6324 - val_accuracy: 0.6504\n",
            "Epoch 147/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6308 - accuracy: 0.6477 - val_loss: 0.6322 - val_accuracy: 0.6504\n",
            "Epoch 148/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6306 - accuracy: 0.6477 - val_loss: 0.6320 - val_accuracy: 0.6504\n",
            "Epoch 149/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6303 - accuracy: 0.6477 - val_loss: 0.6318 - val_accuracy: 0.6504\n",
            "Epoch 150/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6301 - accuracy: 0.6477 - val_loss: 0.6316 - val_accuracy: 0.6504\n",
            "Epoch 151/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6297 - accuracy: 0.6477 - val_loss: 0.6314 - val_accuracy: 0.6504\n",
            "Epoch 152/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6294 - accuracy: 0.6477 - val_loss: 0.6311 - val_accuracy: 0.6504\n",
            "Epoch 153/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6290 - accuracy: 0.6477 - val_loss: 0.6309 - val_accuracy: 0.6504\n",
            "Epoch 154/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6288 - accuracy: 0.6477 - val_loss: 0.6306 - val_accuracy: 0.6504\n",
            "Epoch 155/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6284 - accuracy: 0.6477 - val_loss: 0.6303 - val_accuracy: 0.6504\n",
            "Epoch 156/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6280 - accuracy: 0.6477 - val_loss: 0.6301 - val_accuracy: 0.6504\n",
            "Epoch 157/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6275 - accuracy: 0.6477 - val_loss: 0.6298 - val_accuracy: 0.6504\n",
            "Epoch 158/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6273 - accuracy: 0.6477 - val_loss: 0.6294 - val_accuracy: 0.6504\n",
            "Epoch 159/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6268 - accuracy: 0.6477 - val_loss: 0.6291 - val_accuracy: 0.6504\n",
            "Epoch 160/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6264 - accuracy: 0.6477 - val_loss: 0.6287 - val_accuracy: 0.6504\n",
            "Epoch 161/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6259 - accuracy: 0.6477 - val_loss: 0.6284 - val_accuracy: 0.6504\n",
            "Epoch 162/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6256 - accuracy: 0.6477 - val_loss: 0.6280 - val_accuracy: 0.6504\n",
            "Epoch 163/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6251 - accuracy: 0.6477 - val_loss: 0.6277 - val_accuracy: 0.6504\n",
            "Epoch 164/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6246 - accuracy: 0.6477 - val_loss: 0.6273 - val_accuracy: 0.6504\n",
            "Epoch 165/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6243 - accuracy: 0.6477 - val_loss: 0.6269 - val_accuracy: 0.6504\n",
            "Epoch 166/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6238 - accuracy: 0.6477 - val_loss: 0.6265 - val_accuracy: 0.6504\n",
            "Epoch 167/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6233 - accuracy: 0.6477 - val_loss: 0.6260 - val_accuracy: 0.6504\n",
            "Epoch 168/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6228 - accuracy: 0.6477 - val_loss: 0.6255 - val_accuracy: 0.6504\n",
            "Epoch 169/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6222 - accuracy: 0.6477 - val_loss: 0.6250 - val_accuracy: 0.6504\n",
            "Epoch 170/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6216 - accuracy: 0.6477 - val_loss: 0.6244 - val_accuracy: 0.6504\n",
            "Epoch 171/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6210 - accuracy: 0.6477 - val_loss: 0.6240 - val_accuracy: 0.6504\n",
            "Epoch 172/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6205 - accuracy: 0.6477 - val_loss: 0.6235 - val_accuracy: 0.6504\n",
            "Epoch 173/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6199 - accuracy: 0.6477 - val_loss: 0.6230 - val_accuracy: 0.6504\n",
            "Epoch 174/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6192 - accuracy: 0.6497 - val_loss: 0.6225 - val_accuracy: 0.6504\n",
            "Epoch 175/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6188 - accuracy: 0.6517 - val_loss: 0.6220 - val_accuracy: 0.6504\n",
            "Epoch 176/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6181 - accuracy: 0.6497 - val_loss: 0.6215 - val_accuracy: 0.6504\n",
            "Epoch 177/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6176 - accuracy: 0.6497 - val_loss: 0.6210 - val_accuracy: 0.6504\n",
            "Epoch 178/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6171 - accuracy: 0.6497 - val_loss: 0.6206 - val_accuracy: 0.6504\n",
            "Epoch 179/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6165 - accuracy: 0.6497 - val_loss: 0.6202 - val_accuracy: 0.6504\n",
            "Epoch 180/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6161 - accuracy: 0.6497 - val_loss: 0.6198 - val_accuracy: 0.6504\n",
            "Epoch 181/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6156 - accuracy: 0.6497 - val_loss: 0.6194 - val_accuracy: 0.6504\n",
            "Epoch 182/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6153 - accuracy: 0.6497 - val_loss: 0.6190 - val_accuracy: 0.6504\n",
            "Epoch 183/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6147 - accuracy: 0.6497 - val_loss: 0.6185 - val_accuracy: 0.6504\n",
            "Epoch 184/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6142 - accuracy: 0.6497 - val_loss: 0.6181 - val_accuracy: 0.6504\n",
            "Epoch 185/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6138 - accuracy: 0.6517 - val_loss: 0.6177 - val_accuracy: 0.6504\n",
            "Epoch 186/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6133 - accuracy: 0.6517 - val_loss: 0.6173 - val_accuracy: 0.6504\n",
            "Epoch 187/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6129 - accuracy: 0.6558 - val_loss: 0.6169 - val_accuracy: 0.6504\n",
            "Epoch 188/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6124 - accuracy: 0.6538 - val_loss: 0.6165 - val_accuracy: 0.6504\n",
            "Epoch 189/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6121 - accuracy: 0.6538 - val_loss: 0.6162 - val_accuracy: 0.6504\n",
            "Epoch 190/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6117 - accuracy: 0.6558 - val_loss: 0.6158 - val_accuracy: 0.6504\n",
            "Epoch 191/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6113 - accuracy: 0.6538 - val_loss: 0.6154 - val_accuracy: 0.6504\n",
            "Epoch 192/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6107 - accuracy: 0.6558 - val_loss: 0.6150 - val_accuracy: 0.6504\n",
            "Epoch 193/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6104 - accuracy: 0.6558 - val_loss: 0.6147 - val_accuracy: 0.6504\n",
            "Epoch 194/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6099 - accuracy: 0.6558 - val_loss: 0.6143 - val_accuracy: 0.6504\n",
            "Epoch 195/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6095 - accuracy: 0.6558 - val_loss: 0.6139 - val_accuracy: 0.6504\n",
            "Epoch 196/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6091 - accuracy: 0.6578 - val_loss: 0.6135 - val_accuracy: 0.6504\n",
            "Epoch 197/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6086 - accuracy: 0.6578 - val_loss: 0.6132 - val_accuracy: 0.6504\n",
            "Epoch 198/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6081 - accuracy: 0.6558 - val_loss: 0.6128 - val_accuracy: 0.6504\n",
            "Epoch 199/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.6077 - accuracy: 0.6578 - val_loss: 0.6124 - val_accuracy: 0.6504\n",
            "Epoch 200/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6072 - accuracy: 0.6558 - val_loss: 0.6120 - val_accuracy: 0.6504\n",
            "Epoch 201/1000\n",
            "491/491 [==============================] - 0s 27us/step - loss: 0.6068 - accuracy: 0.6619 - val_loss: 0.6116 - val_accuracy: 0.6504\n",
            "Epoch 202/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6064 - accuracy: 0.6578 - val_loss: 0.6113 - val_accuracy: 0.6504\n",
            "Epoch 203/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6060 - accuracy: 0.6578 - val_loss: 0.6109 - val_accuracy: 0.6504\n",
            "Epoch 204/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6056 - accuracy: 0.6599 - val_loss: 0.6105 - val_accuracy: 0.6504\n",
            "Epoch 205/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6050 - accuracy: 0.6578 - val_loss: 0.6101 - val_accuracy: 0.6504\n",
            "Epoch 206/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6047 - accuracy: 0.6599 - val_loss: 0.6097 - val_accuracy: 0.6504\n",
            "Epoch 207/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6042 - accuracy: 0.6578 - val_loss: 0.6094 - val_accuracy: 0.6504\n",
            "Epoch 208/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6036 - accuracy: 0.6599 - val_loss: 0.6090 - val_accuracy: 0.6504\n",
            "Epoch 209/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6033 - accuracy: 0.6599 - val_loss: 0.6086 - val_accuracy: 0.6585\n",
            "Epoch 210/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6028 - accuracy: 0.6640 - val_loss: 0.6082 - val_accuracy: 0.6585\n",
            "Epoch 211/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6022 - accuracy: 0.6640 - val_loss: 0.6078 - val_accuracy: 0.6585\n",
            "Epoch 212/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6019 - accuracy: 0.6640 - val_loss: 0.6074 - val_accuracy: 0.6585\n",
            "Epoch 213/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.6014 - accuracy: 0.6619 - val_loss: 0.6070 - val_accuracy: 0.6585\n",
            "Epoch 214/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.6008 - accuracy: 0.6680 - val_loss: 0.6066 - val_accuracy: 0.6585\n",
            "Epoch 215/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6003 - accuracy: 0.6660 - val_loss: 0.6062 - val_accuracy: 0.6585\n",
            "Epoch 216/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6000 - accuracy: 0.6640 - val_loss: 0.6058 - val_accuracy: 0.6585\n",
            "Epoch 217/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5994 - accuracy: 0.6741 - val_loss: 0.6054 - val_accuracy: 0.6585\n",
            "Epoch 218/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5989 - accuracy: 0.6721 - val_loss: 0.6050 - val_accuracy: 0.6585\n",
            "Epoch 219/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5985 - accuracy: 0.6721 - val_loss: 0.6046 - val_accuracy: 0.6585\n",
            "Epoch 220/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5980 - accuracy: 0.6721 - val_loss: 0.6042 - val_accuracy: 0.6585\n",
            "Epoch 221/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5977 - accuracy: 0.6721 - val_loss: 0.6038 - val_accuracy: 0.6667\n",
            "Epoch 222/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5969 - accuracy: 0.6721 - val_loss: 0.6034 - val_accuracy: 0.6748\n",
            "Epoch 223/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5965 - accuracy: 0.6721 - val_loss: 0.6030 - val_accuracy: 0.6829\n",
            "Epoch 224/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5959 - accuracy: 0.6762 - val_loss: 0.6025 - val_accuracy: 0.6829\n",
            "Epoch 225/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5955 - accuracy: 0.6721 - val_loss: 0.6021 - val_accuracy: 0.6829\n",
            "Epoch 226/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5950 - accuracy: 0.6762 - val_loss: 0.6018 - val_accuracy: 0.6829\n",
            "Epoch 227/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5945 - accuracy: 0.6762 - val_loss: 0.6014 - val_accuracy: 0.6748\n",
            "Epoch 228/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5940 - accuracy: 0.6843 - val_loss: 0.6009 - val_accuracy: 0.6748\n",
            "Epoch 229/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5935 - accuracy: 0.6823 - val_loss: 0.6004 - val_accuracy: 0.6829\n",
            "Epoch 230/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5930 - accuracy: 0.6762 - val_loss: 0.6000 - val_accuracy: 0.6748\n",
            "Epoch 231/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5924 - accuracy: 0.6762 - val_loss: 0.5996 - val_accuracy: 0.6748\n",
            "Epoch 232/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5920 - accuracy: 0.6823 - val_loss: 0.5992 - val_accuracy: 0.6748\n",
            "Epoch 233/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5913 - accuracy: 0.6823 - val_loss: 0.5988 - val_accuracy: 0.6748\n",
            "Epoch 234/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5909 - accuracy: 0.6843 - val_loss: 0.5984 - val_accuracy: 0.6748\n",
            "Epoch 235/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5904 - accuracy: 0.6945 - val_loss: 0.5979 - val_accuracy: 0.6748\n",
            "Epoch 236/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5899 - accuracy: 0.6904 - val_loss: 0.5975 - val_accuracy: 0.6748\n",
            "Epoch 237/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5892 - accuracy: 0.6864 - val_loss: 0.5971 - val_accuracy: 0.6748\n",
            "Epoch 238/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5888 - accuracy: 0.6904 - val_loss: 0.5967 - val_accuracy: 0.6667\n",
            "Epoch 239/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5883 - accuracy: 0.6945 - val_loss: 0.5963 - val_accuracy: 0.6748\n",
            "Epoch 240/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5878 - accuracy: 0.6945 - val_loss: 0.5958 - val_accuracy: 0.6748\n",
            "Epoch 241/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5873 - accuracy: 0.6965 - val_loss: 0.5954 - val_accuracy: 0.6829\n",
            "Epoch 242/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5866 - accuracy: 0.6945 - val_loss: 0.5950 - val_accuracy: 0.6829\n",
            "Epoch 243/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5861 - accuracy: 0.6945 - val_loss: 0.5945 - val_accuracy: 0.6829\n",
            "Epoch 244/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5857 - accuracy: 0.6945 - val_loss: 0.5941 - val_accuracy: 0.6829\n",
            "Epoch 245/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5851 - accuracy: 0.6925 - val_loss: 0.5936 - val_accuracy: 0.6829\n",
            "Epoch 246/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5846 - accuracy: 0.6945 - val_loss: 0.5932 - val_accuracy: 0.6829\n",
            "Epoch 247/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5843 - accuracy: 0.6945 - val_loss: 0.5927 - val_accuracy: 0.6829\n",
            "Epoch 248/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5837 - accuracy: 0.6945 - val_loss: 0.5923 - val_accuracy: 0.6829\n",
            "Epoch 249/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5832 - accuracy: 0.6945 - val_loss: 0.5918 - val_accuracy: 0.6829\n",
            "Epoch 250/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5827 - accuracy: 0.6945 - val_loss: 0.5914 - val_accuracy: 0.6829\n",
            "Epoch 251/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5819 - accuracy: 0.6965 - val_loss: 0.5909 - val_accuracy: 0.6748\n",
            "Epoch 252/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5814 - accuracy: 0.6965 - val_loss: 0.5905 - val_accuracy: 0.6748\n",
            "Epoch 253/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5809 - accuracy: 0.6945 - val_loss: 0.5900 - val_accuracy: 0.6667\n",
            "Epoch 254/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5805 - accuracy: 0.6965 - val_loss: 0.5896 - val_accuracy: 0.6667\n",
            "Epoch 255/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5798 - accuracy: 0.6965 - val_loss: 0.5892 - val_accuracy: 0.6667\n",
            "Epoch 256/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5793 - accuracy: 0.6945 - val_loss: 0.5887 - val_accuracy: 0.6667\n",
            "Epoch 257/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5788 - accuracy: 0.6945 - val_loss: 0.5883 - val_accuracy: 0.6748\n",
            "Epoch 258/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5782 - accuracy: 0.6925 - val_loss: 0.5878 - val_accuracy: 0.6829\n",
            "Epoch 259/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5776 - accuracy: 0.6925 - val_loss: 0.5873 - val_accuracy: 0.6829\n",
            "Epoch 260/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5771 - accuracy: 0.6945 - val_loss: 0.5869 - val_accuracy: 0.6911\n",
            "Epoch 261/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5766 - accuracy: 0.6945 - val_loss: 0.5864 - val_accuracy: 0.6829\n",
            "Epoch 262/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5759 - accuracy: 0.6945 - val_loss: 0.5859 - val_accuracy: 0.6829\n",
            "Epoch 263/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5753 - accuracy: 0.6925 - val_loss: 0.5855 - val_accuracy: 0.6829\n",
            "Epoch 264/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5748 - accuracy: 0.6965 - val_loss: 0.5850 - val_accuracy: 0.6829\n",
            "Epoch 265/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5743 - accuracy: 0.6965 - val_loss: 0.5845 - val_accuracy: 0.6829\n",
            "Epoch 266/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5738 - accuracy: 0.6945 - val_loss: 0.5840 - val_accuracy: 0.6829\n",
            "Epoch 267/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5732 - accuracy: 0.7006 - val_loss: 0.5835 - val_accuracy: 0.6829\n",
            "Epoch 268/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5727 - accuracy: 0.7026 - val_loss: 0.5830 - val_accuracy: 0.6829\n",
            "Epoch 269/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5721 - accuracy: 0.6965 - val_loss: 0.5826 - val_accuracy: 0.6829\n",
            "Epoch 270/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5714 - accuracy: 0.7026 - val_loss: 0.5821 - val_accuracy: 0.6829\n",
            "Epoch 271/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5712 - accuracy: 0.7108 - val_loss: 0.5816 - val_accuracy: 0.6911\n",
            "Epoch 272/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5705 - accuracy: 0.7047 - val_loss: 0.5812 - val_accuracy: 0.6992\n",
            "Epoch 273/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5697 - accuracy: 0.7067 - val_loss: 0.5807 - val_accuracy: 0.6992\n",
            "Epoch 274/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5692 - accuracy: 0.7088 - val_loss: 0.5802 - val_accuracy: 0.6992\n",
            "Epoch 275/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5686 - accuracy: 0.7047 - val_loss: 0.5797 - val_accuracy: 0.7073\n",
            "Epoch 276/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5680 - accuracy: 0.7047 - val_loss: 0.5792 - val_accuracy: 0.7073\n",
            "Epoch 277/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5676 - accuracy: 0.7067 - val_loss: 0.5788 - val_accuracy: 0.6911\n",
            "Epoch 278/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5668 - accuracy: 0.7067 - val_loss: 0.5783 - val_accuracy: 0.6911\n",
            "Epoch 279/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5662 - accuracy: 0.7088 - val_loss: 0.5778 - val_accuracy: 0.6911\n",
            "Epoch 280/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5657 - accuracy: 0.7067 - val_loss: 0.5774 - val_accuracy: 0.6911\n",
            "Epoch 281/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5652 - accuracy: 0.7088 - val_loss: 0.5769 - val_accuracy: 0.6911\n",
            "Epoch 282/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5647 - accuracy: 0.7128 - val_loss: 0.5765 - val_accuracy: 0.6911\n",
            "Epoch 283/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5639 - accuracy: 0.7088 - val_loss: 0.5761 - val_accuracy: 0.6911\n",
            "Epoch 284/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5633 - accuracy: 0.7088 - val_loss: 0.5755 - val_accuracy: 0.6911\n",
            "Epoch 285/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5626 - accuracy: 0.7088 - val_loss: 0.5751 - val_accuracy: 0.6911\n",
            "Epoch 286/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5624 - accuracy: 0.7149 - val_loss: 0.5747 - val_accuracy: 0.6911\n",
            "Epoch 287/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5617 - accuracy: 0.7149 - val_loss: 0.5742 - val_accuracy: 0.6911\n",
            "Epoch 288/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.5611 - accuracy: 0.7128 - val_loss: 0.5737 - val_accuracy: 0.6911\n",
            "Epoch 289/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5605 - accuracy: 0.7088 - val_loss: 0.5733 - val_accuracy: 0.6829\n",
            "Epoch 290/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5597 - accuracy: 0.7149 - val_loss: 0.5728 - val_accuracy: 0.6829\n",
            "Epoch 291/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5594 - accuracy: 0.7108 - val_loss: 0.5723 - val_accuracy: 0.6829\n",
            "Epoch 292/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5586 - accuracy: 0.7128 - val_loss: 0.5720 - val_accuracy: 0.6829\n",
            "Epoch 293/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5581 - accuracy: 0.7128 - val_loss: 0.5714 - val_accuracy: 0.6829\n",
            "Epoch 294/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5574 - accuracy: 0.7128 - val_loss: 0.5710 - val_accuracy: 0.6829\n",
            "Epoch 295/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5566 - accuracy: 0.7149 - val_loss: 0.5705 - val_accuracy: 0.6829\n",
            "Epoch 296/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5560 - accuracy: 0.7189 - val_loss: 0.5699 - val_accuracy: 0.6829\n",
            "Epoch 297/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5558 - accuracy: 0.7210 - val_loss: 0.5694 - val_accuracy: 0.6911\n",
            "Epoch 298/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5551 - accuracy: 0.7128 - val_loss: 0.5691 - val_accuracy: 0.6829\n",
            "Epoch 299/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5541 - accuracy: 0.7189 - val_loss: 0.5688 - val_accuracy: 0.6829\n",
            "Epoch 300/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5535 - accuracy: 0.7169 - val_loss: 0.5684 - val_accuracy: 0.6829\n",
            "Epoch 301/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5531 - accuracy: 0.7169 - val_loss: 0.5680 - val_accuracy: 0.6829\n",
            "Epoch 302/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5524 - accuracy: 0.7210 - val_loss: 0.5675 - val_accuracy: 0.6829\n",
            "Epoch 303/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5521 - accuracy: 0.7169 - val_loss: 0.5670 - val_accuracy: 0.6829\n",
            "Epoch 304/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5511 - accuracy: 0.7210 - val_loss: 0.5666 - val_accuracy: 0.6829\n",
            "Epoch 305/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5508 - accuracy: 0.7189 - val_loss: 0.5662 - val_accuracy: 0.6829\n",
            "Epoch 306/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5501 - accuracy: 0.7169 - val_loss: 0.5659 - val_accuracy: 0.6748\n",
            "Epoch 307/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5494 - accuracy: 0.7210 - val_loss: 0.5655 - val_accuracy: 0.6748\n",
            "Epoch 308/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.5489 - accuracy: 0.7210 - val_loss: 0.5649 - val_accuracy: 0.6748\n",
            "Epoch 309/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5481 - accuracy: 0.7230 - val_loss: 0.5644 - val_accuracy: 0.6829\n",
            "Epoch 310/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5478 - accuracy: 0.7230 - val_loss: 0.5640 - val_accuracy: 0.6748\n",
            "Epoch 311/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5471 - accuracy: 0.7230 - val_loss: 0.5636 - val_accuracy: 0.6748\n",
            "Epoch 312/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5464 - accuracy: 0.7271 - val_loss: 0.5631 - val_accuracy: 0.6748\n",
            "Epoch 313/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5458 - accuracy: 0.7230 - val_loss: 0.5627 - val_accuracy: 0.6748\n",
            "Epoch 314/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5454 - accuracy: 0.7291 - val_loss: 0.5624 - val_accuracy: 0.6748\n",
            "Epoch 315/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5448 - accuracy: 0.7271 - val_loss: 0.5619 - val_accuracy: 0.6748\n",
            "Epoch 316/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.5442 - accuracy: 0.7291 - val_loss: 0.5615 - val_accuracy: 0.6829\n",
            "Epoch 317/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5435 - accuracy: 0.7271 - val_loss: 0.5610 - val_accuracy: 0.6829\n",
            "Epoch 318/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5430 - accuracy: 0.7312 - val_loss: 0.5606 - val_accuracy: 0.6829\n",
            "Epoch 319/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5426 - accuracy: 0.7312 - val_loss: 0.5602 - val_accuracy: 0.6829\n",
            "Epoch 320/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5419 - accuracy: 0.7312 - val_loss: 0.5599 - val_accuracy: 0.6911\n",
            "Epoch 321/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5413 - accuracy: 0.7332 - val_loss: 0.5595 - val_accuracy: 0.6911\n",
            "Epoch 322/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5410 - accuracy: 0.7271 - val_loss: 0.5591 - val_accuracy: 0.6911\n",
            "Epoch 323/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5403 - accuracy: 0.7271 - val_loss: 0.5587 - val_accuracy: 0.6911\n",
            "Epoch 324/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5397 - accuracy: 0.7291 - val_loss: 0.5583 - val_accuracy: 0.6911\n",
            "Epoch 325/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5392 - accuracy: 0.7373 - val_loss: 0.5580 - val_accuracy: 0.6829\n",
            "Epoch 326/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5387 - accuracy: 0.7271 - val_loss: 0.5577 - val_accuracy: 0.6829\n",
            "Epoch 327/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5380 - accuracy: 0.7251 - val_loss: 0.5572 - val_accuracy: 0.6829\n",
            "Epoch 328/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5375 - accuracy: 0.7271 - val_loss: 0.5569 - val_accuracy: 0.6829\n",
            "Epoch 329/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5376 - accuracy: 0.7251 - val_loss: 0.5563 - val_accuracy: 0.6829\n",
            "Epoch 330/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5365 - accuracy: 0.7271 - val_loss: 0.5560 - val_accuracy: 0.6829\n",
            "Epoch 331/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5364 - accuracy: 0.7251 - val_loss: 0.5555 - val_accuracy: 0.6829\n",
            "Epoch 332/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5355 - accuracy: 0.7271 - val_loss: 0.5552 - val_accuracy: 0.6829\n",
            "Epoch 333/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5349 - accuracy: 0.7271 - val_loss: 0.5547 - val_accuracy: 0.6911\n",
            "Epoch 334/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5344 - accuracy: 0.7291 - val_loss: 0.5544 - val_accuracy: 0.6911\n",
            "Epoch 335/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5339 - accuracy: 0.7332 - val_loss: 0.5540 - val_accuracy: 0.6829\n",
            "Epoch 336/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5334 - accuracy: 0.7352 - val_loss: 0.5539 - val_accuracy: 0.6748\n",
            "Epoch 337/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5326 - accuracy: 0.7271 - val_loss: 0.5533 - val_accuracy: 0.6829\n",
            "Epoch 338/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5320 - accuracy: 0.7291 - val_loss: 0.5530 - val_accuracy: 0.6748\n",
            "Epoch 339/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5315 - accuracy: 0.7251 - val_loss: 0.5526 - val_accuracy: 0.6748\n",
            "Epoch 340/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5312 - accuracy: 0.7251 - val_loss: 0.5523 - val_accuracy: 0.6748\n",
            "Epoch 341/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5306 - accuracy: 0.7251 - val_loss: 0.5518 - val_accuracy: 0.6829\n",
            "Epoch 342/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5304 - accuracy: 0.7271 - val_loss: 0.5514 - val_accuracy: 0.6911\n",
            "Epoch 343/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5294 - accuracy: 0.7291 - val_loss: 0.5511 - val_accuracy: 0.6911\n",
            "Epoch 344/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5288 - accuracy: 0.7271 - val_loss: 0.5507 - val_accuracy: 0.6911\n",
            "Epoch 345/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5283 - accuracy: 0.7271 - val_loss: 0.5504 - val_accuracy: 0.6748\n",
            "Epoch 346/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5280 - accuracy: 0.7291 - val_loss: 0.5501 - val_accuracy: 0.6748\n",
            "Epoch 347/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5276 - accuracy: 0.7271 - val_loss: 0.5498 - val_accuracy: 0.6748\n",
            "Epoch 348/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5268 - accuracy: 0.7230 - val_loss: 0.5495 - val_accuracy: 0.6748\n",
            "Epoch 349/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.5265 - accuracy: 0.7251 - val_loss: 0.5492 - val_accuracy: 0.6748\n",
            "Epoch 350/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5258 - accuracy: 0.7251 - val_loss: 0.5487 - val_accuracy: 0.6829\n",
            "Epoch 351/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5255 - accuracy: 0.7251 - val_loss: 0.5484 - val_accuracy: 0.6748\n",
            "Epoch 352/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5250 - accuracy: 0.7251 - val_loss: 0.5481 - val_accuracy: 0.6748\n",
            "Epoch 353/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5244 - accuracy: 0.7271 - val_loss: 0.5478 - val_accuracy: 0.6748\n",
            "Epoch 354/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5239 - accuracy: 0.7251 - val_loss: 0.5474 - val_accuracy: 0.6829\n",
            "Epoch 355/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5237 - accuracy: 0.7271 - val_loss: 0.5472 - val_accuracy: 0.6748\n",
            "Epoch 356/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5232 - accuracy: 0.7230 - val_loss: 0.5469 - val_accuracy: 0.6748\n",
            "Epoch 357/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5225 - accuracy: 0.7210 - val_loss: 0.5464 - val_accuracy: 0.6829\n",
            "Epoch 358/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5222 - accuracy: 0.7230 - val_loss: 0.5460 - val_accuracy: 0.6829\n",
            "Epoch 359/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5212 - accuracy: 0.7251 - val_loss: 0.5458 - val_accuracy: 0.6748\n",
            "Epoch 360/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5213 - accuracy: 0.7271 - val_loss: 0.5455 - val_accuracy: 0.6829\n",
            "Epoch 361/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5203 - accuracy: 0.7189 - val_loss: 0.5451 - val_accuracy: 0.6829\n",
            "Epoch 362/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.5201 - accuracy: 0.7251 - val_loss: 0.5447 - val_accuracy: 0.6829\n",
            "Epoch 363/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5195 - accuracy: 0.7230 - val_loss: 0.5444 - val_accuracy: 0.6829\n",
            "Epoch 364/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5191 - accuracy: 0.7291 - val_loss: 0.5440 - val_accuracy: 0.6829\n",
            "Epoch 365/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5188 - accuracy: 0.7210 - val_loss: 0.5438 - val_accuracy: 0.6829\n",
            "Epoch 366/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5181 - accuracy: 0.7251 - val_loss: 0.5435 - val_accuracy: 0.6829\n",
            "Epoch 367/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5175 - accuracy: 0.7230 - val_loss: 0.5434 - val_accuracy: 0.6829\n",
            "Epoch 368/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5175 - accuracy: 0.7251 - val_loss: 0.5431 - val_accuracy: 0.6911\n",
            "Epoch 369/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.5168 - accuracy: 0.7291 - val_loss: 0.5428 - val_accuracy: 0.6911\n",
            "Epoch 370/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5163 - accuracy: 0.7251 - val_loss: 0.5427 - val_accuracy: 0.6748\n",
            "Epoch 371/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5157 - accuracy: 0.7251 - val_loss: 0.5422 - val_accuracy: 0.6911\n",
            "Epoch 372/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5153 - accuracy: 0.7291 - val_loss: 0.5418 - val_accuracy: 0.6829\n",
            "Epoch 373/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5147 - accuracy: 0.7271 - val_loss: 0.5416 - val_accuracy: 0.6911\n",
            "Epoch 374/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5145 - accuracy: 0.7271 - val_loss: 0.5413 - val_accuracy: 0.6911\n",
            "Epoch 375/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5145 - accuracy: 0.7271 - val_loss: 0.5411 - val_accuracy: 0.6911\n",
            "Epoch 376/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5139 - accuracy: 0.7291 - val_loss: 0.5407 - val_accuracy: 0.6911\n",
            "Epoch 377/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5133 - accuracy: 0.7271 - val_loss: 0.5404 - val_accuracy: 0.6911\n",
            "Epoch 378/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5129 - accuracy: 0.7271 - val_loss: 0.5401 - val_accuracy: 0.6911\n",
            "Epoch 379/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5125 - accuracy: 0.7312 - val_loss: 0.5399 - val_accuracy: 0.7073\n",
            "Epoch 380/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.5122 - accuracy: 0.7312 - val_loss: 0.5396 - val_accuracy: 0.6992\n",
            "Epoch 381/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5116 - accuracy: 0.7352 - val_loss: 0.5391 - val_accuracy: 0.6911\n",
            "Epoch 382/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5113 - accuracy: 0.7312 - val_loss: 0.5388 - val_accuracy: 0.6911\n",
            "Epoch 383/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5108 - accuracy: 0.7291 - val_loss: 0.5386 - val_accuracy: 0.6992\n",
            "Epoch 384/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5101 - accuracy: 0.7352 - val_loss: 0.5382 - val_accuracy: 0.6911\n",
            "Epoch 385/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5098 - accuracy: 0.7312 - val_loss: 0.5379 - val_accuracy: 0.6911\n",
            "Epoch 386/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5095 - accuracy: 0.7291 - val_loss: 0.5378 - val_accuracy: 0.6992\n",
            "Epoch 387/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5090 - accuracy: 0.7312 - val_loss: 0.5376 - val_accuracy: 0.7073\n",
            "Epoch 388/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5087 - accuracy: 0.7332 - val_loss: 0.5374 - val_accuracy: 0.7073\n",
            "Epoch 389/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5081 - accuracy: 0.7332 - val_loss: 0.5374 - val_accuracy: 0.7154\n",
            "Epoch 390/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5080 - accuracy: 0.7373 - val_loss: 0.5372 - val_accuracy: 0.7236\n",
            "Epoch 391/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5072 - accuracy: 0.7373 - val_loss: 0.5372 - val_accuracy: 0.7236\n",
            "Epoch 392/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5073 - accuracy: 0.7393 - val_loss: 0.5372 - val_accuracy: 0.7236\n",
            "Epoch 393/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5066 - accuracy: 0.7352 - val_loss: 0.5366 - val_accuracy: 0.7317\n",
            "Epoch 394/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5061 - accuracy: 0.7393 - val_loss: 0.5363 - val_accuracy: 0.7317\n",
            "Epoch 395/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5057 - accuracy: 0.7332 - val_loss: 0.5356 - val_accuracy: 0.7073\n",
            "Epoch 396/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5052 - accuracy: 0.7393 - val_loss: 0.5356 - val_accuracy: 0.7154\n",
            "Epoch 397/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5048 - accuracy: 0.7393 - val_loss: 0.5354 - val_accuracy: 0.7154\n",
            "Epoch 398/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5049 - accuracy: 0.7413 - val_loss: 0.5352 - val_accuracy: 0.7236\n",
            "Epoch 399/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5041 - accuracy: 0.7352 - val_loss: 0.5351 - val_accuracy: 0.7317\n",
            "Epoch 400/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5039 - accuracy: 0.7393 - val_loss: 0.5348 - val_accuracy: 0.7317\n",
            "Epoch 401/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5033 - accuracy: 0.7393 - val_loss: 0.5347 - val_accuracy: 0.7317\n",
            "Epoch 402/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.5031 - accuracy: 0.7373 - val_loss: 0.5342 - val_accuracy: 0.7154\n",
            "Epoch 403/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5027 - accuracy: 0.7434 - val_loss: 0.5339 - val_accuracy: 0.7154\n",
            "Epoch 404/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5022 - accuracy: 0.7434 - val_loss: 0.5337 - val_accuracy: 0.7154\n",
            "Epoch 405/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5021 - accuracy: 0.7434 - val_loss: 0.5336 - val_accuracy: 0.7236\n",
            "Epoch 406/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5013 - accuracy: 0.7373 - val_loss: 0.5334 - val_accuracy: 0.7236\n",
            "Epoch 407/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5015 - accuracy: 0.7434 - val_loss: 0.5331 - val_accuracy: 0.7317\n",
            "Epoch 408/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5006 - accuracy: 0.7434 - val_loss: 0.5328 - val_accuracy: 0.7317\n",
            "Epoch 409/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5003 - accuracy: 0.7413 - val_loss: 0.5326 - val_accuracy: 0.7317\n",
            "Epoch 410/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5003 - accuracy: 0.7454 - val_loss: 0.5324 - val_accuracy: 0.7317\n",
            "Epoch 411/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.4997 - accuracy: 0.7393 - val_loss: 0.5323 - val_accuracy: 0.7236\n",
            "Epoch 412/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4992 - accuracy: 0.7393 - val_loss: 0.5320 - val_accuracy: 0.7317\n",
            "Epoch 413/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4990 - accuracy: 0.7413 - val_loss: 0.5317 - val_accuracy: 0.7317\n",
            "Epoch 414/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4992 - accuracy: 0.7352 - val_loss: 0.5315 - val_accuracy: 0.7236\n",
            "Epoch 415/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4983 - accuracy: 0.7475 - val_loss: 0.5315 - val_accuracy: 0.7398\n",
            "Epoch 416/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4978 - accuracy: 0.7434 - val_loss: 0.5316 - val_accuracy: 0.7236\n",
            "Epoch 417/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4977 - accuracy: 0.7413 - val_loss: 0.5312 - val_accuracy: 0.7398\n",
            "Epoch 418/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4972 - accuracy: 0.7434 - val_loss: 0.5312 - val_accuracy: 0.7236\n",
            "Epoch 419/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4970 - accuracy: 0.7413 - val_loss: 0.5307 - val_accuracy: 0.7317\n",
            "Epoch 420/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4966 - accuracy: 0.7393 - val_loss: 0.5305 - val_accuracy: 0.7317\n",
            "Epoch 421/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4960 - accuracy: 0.7475 - val_loss: 0.5304 - val_accuracy: 0.7398\n",
            "Epoch 422/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4958 - accuracy: 0.7393 - val_loss: 0.5302 - val_accuracy: 0.7317\n",
            "Epoch 423/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4956 - accuracy: 0.7475 - val_loss: 0.5301 - val_accuracy: 0.7236\n",
            "Epoch 424/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4953 - accuracy: 0.7454 - val_loss: 0.5298 - val_accuracy: 0.7317\n",
            "Epoch 425/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4950 - accuracy: 0.7413 - val_loss: 0.5295 - val_accuracy: 0.7317\n",
            "Epoch 426/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4945 - accuracy: 0.7454 - val_loss: 0.5293 - val_accuracy: 0.7317\n",
            "Epoch 427/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4943 - accuracy: 0.7413 - val_loss: 0.5291 - val_accuracy: 0.7236\n",
            "Epoch 428/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4941 - accuracy: 0.7454 - val_loss: 0.5289 - val_accuracy: 0.7154\n",
            "Epoch 429/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4935 - accuracy: 0.7475 - val_loss: 0.5291 - val_accuracy: 0.7236\n",
            "Epoch 430/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4936 - accuracy: 0.7393 - val_loss: 0.5289 - val_accuracy: 0.7236\n",
            "Epoch 431/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4930 - accuracy: 0.7454 - val_loss: 0.5286 - val_accuracy: 0.7236\n",
            "Epoch 432/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4922 - accuracy: 0.7495 - val_loss: 0.5282 - val_accuracy: 0.7154\n",
            "Epoch 433/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4923 - accuracy: 0.7536 - val_loss: 0.5279 - val_accuracy: 0.7154\n",
            "Epoch 434/1000\n",
            "491/491 [==============================] - 0s 52us/step - loss: 0.4915 - accuracy: 0.7515 - val_loss: 0.5277 - val_accuracy: 0.7154\n",
            "Epoch 435/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4911 - accuracy: 0.7536 - val_loss: 0.5275 - val_accuracy: 0.7154\n",
            "Epoch 436/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4914 - accuracy: 0.7556 - val_loss: 0.5275 - val_accuracy: 0.7154\n",
            "Epoch 437/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4909 - accuracy: 0.7556 - val_loss: 0.5272 - val_accuracy: 0.7154\n",
            "Epoch 438/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4907 - accuracy: 0.7576 - val_loss: 0.5270 - val_accuracy: 0.7073\n",
            "Epoch 439/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7495 - val_loss: 0.5268 - val_accuracy: 0.7073\n",
            "Epoch 440/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7536 - val_loss: 0.5267 - val_accuracy: 0.7073\n",
            "Epoch 441/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4895 - accuracy: 0.7576 - val_loss: 0.5266 - val_accuracy: 0.6992\n",
            "Epoch 442/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4896 - accuracy: 0.7556 - val_loss: 0.5264 - val_accuracy: 0.7073\n",
            "Epoch 443/1000\n",
            "491/491 [==============================] - 0s 49us/step - loss: 0.4888 - accuracy: 0.7536 - val_loss: 0.5263 - val_accuracy: 0.7154\n",
            "Epoch 444/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4885 - accuracy: 0.7576 - val_loss: 0.5262 - val_accuracy: 0.7154\n",
            "Epoch 445/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4886 - accuracy: 0.7536 - val_loss: 0.5261 - val_accuracy: 0.7154\n",
            "Epoch 446/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.4879 - accuracy: 0.7597 - val_loss: 0.5260 - val_accuracy: 0.7154\n",
            "Epoch 447/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4879 - accuracy: 0.7576 - val_loss: 0.5259 - val_accuracy: 0.7154\n",
            "Epoch 448/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4875 - accuracy: 0.7597 - val_loss: 0.5258 - val_accuracy: 0.7073\n",
            "Epoch 449/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4876 - accuracy: 0.7617 - val_loss: 0.5258 - val_accuracy: 0.7154\n",
            "Epoch 450/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4869 - accuracy: 0.7617 - val_loss: 0.5258 - val_accuracy: 0.7154\n",
            "Epoch 451/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4868 - accuracy: 0.7597 - val_loss: 0.5255 - val_accuracy: 0.7154\n",
            "Epoch 452/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4866 - accuracy: 0.7637 - val_loss: 0.5253 - val_accuracy: 0.7154\n",
            "Epoch 453/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4870 - accuracy: 0.7576 - val_loss: 0.5252 - val_accuracy: 0.7154\n",
            "Epoch 454/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4862 - accuracy: 0.7576 - val_loss: 0.5251 - val_accuracy: 0.7154\n",
            "Epoch 455/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4856 - accuracy: 0.7617 - val_loss: 0.5252 - val_accuracy: 0.7154\n",
            "Epoch 456/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4856 - accuracy: 0.7637 - val_loss: 0.5249 - val_accuracy: 0.7154\n",
            "Epoch 457/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4853 - accuracy: 0.7637 - val_loss: 0.5248 - val_accuracy: 0.7073\n",
            "Epoch 458/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.4850 - accuracy: 0.7617 - val_loss: 0.5247 - val_accuracy: 0.7154\n",
            "Epoch 459/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4845 - accuracy: 0.7637 - val_loss: 0.5246 - val_accuracy: 0.7154\n",
            "Epoch 460/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4848 - accuracy: 0.7617 - val_loss: 0.5245 - val_accuracy: 0.7073\n",
            "Epoch 461/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4841 - accuracy: 0.7597 - val_loss: 0.5245 - val_accuracy: 0.7154\n",
            "Epoch 462/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4842 - accuracy: 0.7617 - val_loss: 0.5243 - val_accuracy: 0.7154\n",
            "Epoch 463/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4838 - accuracy: 0.7617 - val_loss: 0.5243 - val_accuracy: 0.7073\n",
            "Epoch 464/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4836 - accuracy: 0.7617 - val_loss: 0.5242 - val_accuracy: 0.7154\n",
            "Epoch 465/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4835 - accuracy: 0.7637 - val_loss: 0.5241 - val_accuracy: 0.7154\n",
            "Epoch 466/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4830 - accuracy: 0.7678 - val_loss: 0.5240 - val_accuracy: 0.7154\n",
            "Epoch 467/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4829 - accuracy: 0.7678 - val_loss: 0.5239 - val_accuracy: 0.7073\n",
            "Epoch 468/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4828 - accuracy: 0.7678 - val_loss: 0.5238 - val_accuracy: 0.7154\n",
            "Epoch 469/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4823 - accuracy: 0.7658 - val_loss: 0.5238 - val_accuracy: 0.7154\n",
            "Epoch 470/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4824 - accuracy: 0.7637 - val_loss: 0.5237 - val_accuracy: 0.7154\n",
            "Epoch 471/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4818 - accuracy: 0.7678 - val_loss: 0.5236 - val_accuracy: 0.7154\n",
            "Epoch 472/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4814 - accuracy: 0.7699 - val_loss: 0.5235 - val_accuracy: 0.7154\n",
            "Epoch 473/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4812 - accuracy: 0.7658 - val_loss: 0.5234 - val_accuracy: 0.7154\n",
            "Epoch 474/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4814 - accuracy: 0.7678 - val_loss: 0.5234 - val_accuracy: 0.7154\n",
            "Epoch 475/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4812 - accuracy: 0.7637 - val_loss: 0.5234 - val_accuracy: 0.7154\n",
            "Epoch 476/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4805 - accuracy: 0.7678 - val_loss: 0.5235 - val_accuracy: 0.7154\n",
            "Epoch 477/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4804 - accuracy: 0.7658 - val_loss: 0.5231 - val_accuracy: 0.7154\n",
            "Epoch 478/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4801 - accuracy: 0.7658 - val_loss: 0.5231 - val_accuracy: 0.7154\n",
            "Epoch 479/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4800 - accuracy: 0.7658 - val_loss: 0.5230 - val_accuracy: 0.7154\n",
            "Epoch 480/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4800 - accuracy: 0.7658 - val_loss: 0.5229 - val_accuracy: 0.7154\n",
            "Epoch 481/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4799 - accuracy: 0.7678 - val_loss: 0.5228 - val_accuracy: 0.7154\n",
            "Epoch 482/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4794 - accuracy: 0.7658 - val_loss: 0.5228 - val_accuracy: 0.7154\n",
            "Epoch 483/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4790 - accuracy: 0.7678 - val_loss: 0.5228 - val_accuracy: 0.7154\n",
            "Epoch 484/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4794 - accuracy: 0.7658 - val_loss: 0.5227 - val_accuracy: 0.7154\n",
            "Epoch 485/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4786 - accuracy: 0.7678 - val_loss: 0.5226 - val_accuracy: 0.7154\n",
            "Epoch 486/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4785 - accuracy: 0.7678 - val_loss: 0.5225 - val_accuracy: 0.7154\n",
            "Epoch 487/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4781 - accuracy: 0.7699 - val_loss: 0.5225 - val_accuracy: 0.7154\n",
            "Epoch 488/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4781 - accuracy: 0.7678 - val_loss: 0.5224 - val_accuracy: 0.7154\n",
            "Epoch 489/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4777 - accuracy: 0.7699 - val_loss: 0.5224 - val_accuracy: 0.7154\n",
            "Epoch 490/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4779 - accuracy: 0.7699 - val_loss: 0.5223 - val_accuracy: 0.7154\n",
            "Epoch 491/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4774 - accuracy: 0.7678 - val_loss: 0.5223 - val_accuracy: 0.7154\n",
            "Epoch 492/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4772 - accuracy: 0.7699 - val_loss: 0.5222 - val_accuracy: 0.7154\n",
            "Epoch 493/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4772 - accuracy: 0.7719 - val_loss: 0.5222 - val_accuracy: 0.7154\n",
            "Epoch 494/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4774 - accuracy: 0.7719 - val_loss: 0.5221 - val_accuracy: 0.7154\n",
            "Epoch 495/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4766 - accuracy: 0.7678 - val_loss: 0.5221 - val_accuracy: 0.7154\n",
            "Epoch 496/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4764 - accuracy: 0.7699 - val_loss: 0.5220 - val_accuracy: 0.7154\n",
            "Epoch 497/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4767 - accuracy: 0.7658 - val_loss: 0.5220 - val_accuracy: 0.7154\n",
            "Epoch 498/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4763 - accuracy: 0.7658 - val_loss: 0.5220 - val_accuracy: 0.7236\n",
            "Epoch 499/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4762 - accuracy: 0.7699 - val_loss: 0.5221 - val_accuracy: 0.7317\n",
            "Epoch 500/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4758 - accuracy: 0.7678 - val_loss: 0.5219 - val_accuracy: 0.7236\n",
            "Epoch 501/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4760 - accuracy: 0.7658 - val_loss: 0.5219 - val_accuracy: 0.7236\n",
            "Epoch 502/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4753 - accuracy: 0.7699 - val_loss: 0.5218 - val_accuracy: 0.7236\n",
            "Epoch 503/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4758 - accuracy: 0.7699 - val_loss: 0.5221 - val_accuracy: 0.7317\n",
            "Epoch 504/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4749 - accuracy: 0.7699 - val_loss: 0.5220 - val_accuracy: 0.7317\n",
            "Epoch 505/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4753 - accuracy: 0.7678 - val_loss: 0.5223 - val_accuracy: 0.7317\n",
            "Epoch 506/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4749 - accuracy: 0.7658 - val_loss: 0.5218 - val_accuracy: 0.7236\n",
            "Epoch 507/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4743 - accuracy: 0.7637 - val_loss: 0.5217 - val_accuracy: 0.7154\n",
            "Epoch 508/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4742 - accuracy: 0.7719 - val_loss: 0.5217 - val_accuracy: 0.7154\n",
            "Epoch 509/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4740 - accuracy: 0.7719 - val_loss: 0.5215 - val_accuracy: 0.7236\n",
            "Epoch 510/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4741 - accuracy: 0.7678 - val_loss: 0.5215 - val_accuracy: 0.7236\n",
            "Epoch 511/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4749 - accuracy: 0.7678 - val_loss: 0.5215 - val_accuracy: 0.7236\n",
            "Epoch 512/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4739 - accuracy: 0.7658 - val_loss: 0.5214 - val_accuracy: 0.7236\n",
            "Epoch 513/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4741 - accuracy: 0.7699 - val_loss: 0.5215 - val_accuracy: 0.7236\n",
            "Epoch 514/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4737 - accuracy: 0.7678 - val_loss: 0.5214 - val_accuracy: 0.7236\n",
            "Epoch 515/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4733 - accuracy: 0.7719 - val_loss: 0.5216 - val_accuracy: 0.7317\n",
            "Epoch 516/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4730 - accuracy: 0.7658 - val_loss: 0.5214 - val_accuracy: 0.7236\n",
            "Epoch 517/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4731 - accuracy: 0.7719 - val_loss: 0.5214 - val_accuracy: 0.7317\n",
            "Epoch 518/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4727 - accuracy: 0.7678 - val_loss: 0.5213 - val_accuracy: 0.7236\n",
            "Epoch 519/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4727 - accuracy: 0.7699 - val_loss: 0.5212 - val_accuracy: 0.7236\n",
            "Epoch 520/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4724 - accuracy: 0.7658 - val_loss: 0.5213 - val_accuracy: 0.7317\n",
            "Epoch 521/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4729 - accuracy: 0.7678 - val_loss: 0.5212 - val_accuracy: 0.7236\n",
            "Epoch 522/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4718 - accuracy: 0.7719 - val_loss: 0.5211 - val_accuracy: 0.7236\n",
            "Epoch 523/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4716 - accuracy: 0.7699 - val_loss: 0.5211 - val_accuracy: 0.7236\n",
            "Epoch 524/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4717 - accuracy: 0.7678 - val_loss: 0.5211 - val_accuracy: 0.7236\n",
            "Epoch 525/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4722 - accuracy: 0.7739 - val_loss: 0.5210 - val_accuracy: 0.7236\n",
            "Epoch 526/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4710 - accuracy: 0.7719 - val_loss: 0.5211 - val_accuracy: 0.7236\n",
            "Epoch 527/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4707 - accuracy: 0.7719 - val_loss: 0.5210 - val_accuracy: 0.7236\n",
            "Epoch 528/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4709 - accuracy: 0.7699 - val_loss: 0.5211 - val_accuracy: 0.7317\n",
            "Epoch 529/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4711 - accuracy: 0.7678 - val_loss: 0.5210 - val_accuracy: 0.7236\n",
            "Epoch 530/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4711 - accuracy: 0.7699 - val_loss: 0.5210 - val_accuracy: 0.7236\n",
            "Epoch 531/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4711 - accuracy: 0.7678 - val_loss: 0.5209 - val_accuracy: 0.7236\n",
            "Epoch 532/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4708 - accuracy: 0.7699 - val_loss: 0.5209 - val_accuracy: 0.7236\n",
            "Epoch 533/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4702 - accuracy: 0.7739 - val_loss: 0.5211 - val_accuracy: 0.7317\n",
            "Epoch 534/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4702 - accuracy: 0.7719 - val_loss: 0.5210 - val_accuracy: 0.7317\n",
            "Epoch 535/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4704 - accuracy: 0.7719 - val_loss: 0.5209 - val_accuracy: 0.7236\n",
            "Epoch 536/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4695 - accuracy: 0.7719 - val_loss: 0.5209 - val_accuracy: 0.7317\n",
            "Epoch 537/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4696 - accuracy: 0.7739 - val_loss: 0.5208 - val_accuracy: 0.7236\n",
            "Epoch 538/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4695 - accuracy: 0.7719 - val_loss: 0.5208 - val_accuracy: 0.7236\n",
            "Epoch 539/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4694 - accuracy: 0.7719 - val_loss: 0.5209 - val_accuracy: 0.7236\n",
            "Epoch 540/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4693 - accuracy: 0.7719 - val_loss: 0.5211 - val_accuracy: 0.7317\n",
            "Epoch 541/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4692 - accuracy: 0.7719 - val_loss: 0.5209 - val_accuracy: 0.7317\n",
            "Epoch 542/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4690 - accuracy: 0.7719 - val_loss: 0.5209 - val_accuracy: 0.7317\n",
            "Epoch 543/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4686 - accuracy: 0.7719 - val_loss: 0.5211 - val_accuracy: 0.7317\n",
            "Epoch 544/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4686 - accuracy: 0.7699 - val_loss: 0.5214 - val_accuracy: 0.7317\n",
            "Epoch 545/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4686 - accuracy: 0.7699 - val_loss: 0.5209 - val_accuracy: 0.7317\n",
            "Epoch 546/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4682 - accuracy: 0.7739 - val_loss: 0.5209 - val_accuracy: 0.7317\n",
            "Epoch 547/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4689 - accuracy: 0.7739 - val_loss: 0.5210 - val_accuracy: 0.7317\n",
            "Epoch 548/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4680 - accuracy: 0.7739 - val_loss: 0.5206 - val_accuracy: 0.7236\n",
            "Epoch 549/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4687 - accuracy: 0.7719 - val_loss: 0.5207 - val_accuracy: 0.7317\n",
            "Epoch 550/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4676 - accuracy: 0.7739 - val_loss: 0.5208 - val_accuracy: 0.7317\n",
            "Epoch 551/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4681 - accuracy: 0.7719 - val_loss: 0.5207 - val_accuracy: 0.7317\n",
            "Epoch 552/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4672 - accuracy: 0.7719 - val_loss: 0.5206 - val_accuracy: 0.7236\n",
            "Epoch 553/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4673 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 554/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4671 - accuracy: 0.7739 - val_loss: 0.5206 - val_accuracy: 0.7236\n",
            "Epoch 555/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4672 - accuracy: 0.7699 - val_loss: 0.5206 - val_accuracy: 0.7236\n",
            "Epoch 556/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4673 - accuracy: 0.7719 - val_loss: 0.5206 - val_accuracy: 0.7317\n",
            "Epoch 557/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4669 - accuracy: 0.7739 - val_loss: 0.5206 - val_accuracy: 0.7317\n",
            "Epoch 558/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4665 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 559/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4663 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 560/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4664 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 561/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4663 - accuracy: 0.7719 - val_loss: 0.5206 - val_accuracy: 0.7317\n",
            "Epoch 562/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4663 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 563/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4660 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 564/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4662 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 565/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4667 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7317\n",
            "Epoch 566/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4654 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7317\n",
            "Epoch 567/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4656 - accuracy: 0.7780 - val_loss: 0.5206 - val_accuracy: 0.7317\n",
            "Epoch 568/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4655 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7317\n",
            "Epoch 569/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4656 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7317\n",
            "Epoch 570/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4658 - accuracy: 0.7739 - val_loss: 0.5204 - val_accuracy: 0.7317\n",
            "Epoch 571/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4650 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7317\n",
            "Epoch 572/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4654 - accuracy: 0.7739 - val_loss: 0.5204 - val_accuracy: 0.7317\n",
            "Epoch 573/1000\n",
            "491/491 [==============================] - 0s 28us/step - loss: 0.4646 - accuracy: 0.7780 - val_loss: 0.5204 - val_accuracy: 0.7236\n",
            "Epoch 574/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4655 - accuracy: 0.7739 - val_loss: 0.5204 - val_accuracy: 0.7236\n",
            "Epoch 575/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4646 - accuracy: 0.7719 - val_loss: 0.5204 - val_accuracy: 0.7236\n",
            "Epoch 576/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4651 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 577/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7317\n",
            "Epoch 578/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 579/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4644 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 580/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4639 - accuracy: 0.7719 - val_loss: 0.5205 - val_accuracy: 0.7317\n",
            "Epoch 581/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4644 - accuracy: 0.7739 - val_loss: 0.5207 - val_accuracy: 0.7236\n",
            "Epoch 582/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4638 - accuracy: 0.7739 - val_loss: 0.5204 - val_accuracy: 0.7317\n",
            "Epoch 583/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4639 - accuracy: 0.7739 - val_loss: 0.5204 - val_accuracy: 0.7398\n",
            "Epoch 584/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4637 - accuracy: 0.7780 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 585/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4636 - accuracy: 0.7780 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 586/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4642 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 587/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4634 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7317\n",
            "Epoch 588/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4633 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 589/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4633 - accuracy: 0.7780 - val_loss: 0.5206 - val_accuracy: 0.7236\n",
            "Epoch 590/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4633 - accuracy: 0.7780 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 591/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4631 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 592/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4626 - accuracy: 0.7719 - val_loss: 0.5209 - val_accuracy: 0.7480\n",
            "Epoch 593/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4630 - accuracy: 0.7780 - val_loss: 0.5208 - val_accuracy: 0.7398\n",
            "Epoch 594/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4626 - accuracy: 0.7780 - val_loss: 0.5208 - val_accuracy: 0.7398\n",
            "Epoch 595/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4621 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 596/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4620 - accuracy: 0.7780 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 597/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4621 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7398\n",
            "Epoch 598/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7236\n",
            "Epoch 599/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4619 - accuracy: 0.7780 - val_loss: 0.5206 - val_accuracy: 0.7236\n",
            "Epoch 600/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7398\n",
            "Epoch 601/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
            "Epoch 602/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4618 - accuracy: 0.7800 - val_loss: 0.5207 - val_accuracy: 0.7236\n",
            "Epoch 603/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 604/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4620 - accuracy: 0.7780 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 605/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4610 - accuracy: 0.7800 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 606/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4610 - accuracy: 0.7780 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
            "Epoch 607/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4608 - accuracy: 0.7821 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 608/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4608 - accuracy: 0.7780 - val_loss: 0.5209 - val_accuracy: 0.7236\n",
            "Epoch 609/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4614 - accuracy: 0.7780 - val_loss: 0.5207 - val_accuracy: 0.7236\n",
            "Epoch 610/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4614 - accuracy: 0.7800 - val_loss: 0.5207 - val_accuracy: 0.7317\n",
            "Epoch 611/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4611 - accuracy: 0.7800 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 612/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4603 - accuracy: 0.7780 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
            "Epoch 613/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
            "Epoch 614/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4602 - accuracy: 0.7821 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
            "Epoch 615/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4602 - accuracy: 0.7821 - val_loss: 0.5208 - val_accuracy: 0.7236\n",
            "Epoch 616/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7317\n",
            "Epoch 617/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4600 - accuracy: 0.7780 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 618/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4619 - accuracy: 0.7780 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 619/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4598 - accuracy: 0.7780 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
            "Epoch 620/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 621/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
            "Epoch 622/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4596 - accuracy: 0.7821 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
            "Epoch 623/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4602 - accuracy: 0.7821 - val_loss: 0.5208 - val_accuracy: 0.7398\n",
            "Epoch 624/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4596 - accuracy: 0.7780 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
            "Epoch 625/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4594 - accuracy: 0.7821 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 626/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4594 - accuracy: 0.7821 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 627/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4596 - accuracy: 0.7780 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
            "Epoch 628/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4602 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7480\n",
            "Epoch 629/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4596 - accuracy: 0.7841 - val_loss: 0.5209 - val_accuracy: 0.7398\n",
            "Epoch 630/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4593 - accuracy: 0.7821 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
            "Epoch 631/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4590 - accuracy: 0.7821 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
            "Epoch 632/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4588 - accuracy: 0.7841 - val_loss: 0.5207 - val_accuracy: 0.7480\n",
            "Epoch 633/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4589 - accuracy: 0.7841 - val_loss: 0.5207 - val_accuracy: 0.7480\n",
            "Epoch 634/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4585 - accuracy: 0.7821 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
            "Epoch 635/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4588 - accuracy: 0.7800 - val_loss: 0.5208 - val_accuracy: 0.7398\n",
            "Epoch 636/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4585 - accuracy: 0.7841 - val_loss: 0.5208 - val_accuracy: 0.7398\n",
            "Epoch 637/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4589 - accuracy: 0.7841 - val_loss: 0.5207 - val_accuracy: 0.7480\n",
            "Epoch 638/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4589 - accuracy: 0.7821 - val_loss: 0.5208 - val_accuracy: 0.7398\n",
            "Epoch 639/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4586 - accuracy: 0.7841 - val_loss: 0.5208 - val_accuracy: 0.7398\n",
            "Epoch 640/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4584 - accuracy: 0.7862 - val_loss: 0.5208 - val_accuracy: 0.7480\n",
            "Epoch 641/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4583 - accuracy: 0.7841 - val_loss: 0.5209 - val_accuracy: 0.7398\n",
            "Epoch 642/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4587 - accuracy: 0.7882 - val_loss: 0.5210 - val_accuracy: 0.7398\n",
            "Epoch 643/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4576 - accuracy: 0.7841 - val_loss: 0.5208 - val_accuracy: 0.7398\n",
            "Epoch 644/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4577 - accuracy: 0.7841 - val_loss: 0.5209 - val_accuracy: 0.7398\n",
            "Epoch 645/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4581 - accuracy: 0.7862 - val_loss: 0.5209 - val_accuracy: 0.7480\n",
            "Epoch 646/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4577 - accuracy: 0.7821 - val_loss: 0.5210 - val_accuracy: 0.7398\n",
            "Epoch 647/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4584 - accuracy: 0.7862 - val_loss: 0.5209 - val_accuracy: 0.7398\n",
            "Epoch 648/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4583 - accuracy: 0.7800 - val_loss: 0.5209 - val_accuracy: 0.7480\n",
            "Epoch 649/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4575 - accuracy: 0.7862 - val_loss: 0.5209 - val_accuracy: 0.7398\n",
            "Epoch 650/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4576 - accuracy: 0.7862 - val_loss: 0.5208 - val_accuracy: 0.7480\n",
            "Epoch 651/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4576 - accuracy: 0.7821 - val_loss: 0.5211 - val_accuracy: 0.7398\n",
            "Epoch 652/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4571 - accuracy: 0.7800 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 653/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4583 - accuracy: 0.7821 - val_loss: 0.5211 - val_accuracy: 0.7398\n",
            "Epoch 654/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4577 - accuracy: 0.7841 - val_loss: 0.5209 - val_accuracy: 0.7480\n",
            "Epoch 655/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4572 - accuracy: 0.7862 - val_loss: 0.5211 - val_accuracy: 0.7398\n",
            "Epoch 656/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4571 - accuracy: 0.7739 - val_loss: 0.5209 - val_accuracy: 0.7480\n",
            "Epoch 657/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4571 - accuracy: 0.7821 - val_loss: 0.5210 - val_accuracy: 0.7398\n",
            "Epoch 658/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4570 - accuracy: 0.7862 - val_loss: 0.5209 - val_accuracy: 0.7480\n",
            "Epoch 659/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4575 - accuracy: 0.7821 - val_loss: 0.5209 - val_accuracy: 0.7480\n",
            "Epoch 660/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4571 - accuracy: 0.7882 - val_loss: 0.5209 - val_accuracy: 0.7480\n",
            "Epoch 661/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4566 - accuracy: 0.7841 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 662/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4568 - accuracy: 0.7800 - val_loss: 0.5209 - val_accuracy: 0.7480\n",
            "Epoch 663/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4571 - accuracy: 0.7821 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 664/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4567 - accuracy: 0.7841 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 665/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4570 - accuracy: 0.7800 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 666/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4565 - accuracy: 0.7862 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 667/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4559 - accuracy: 0.7862 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 668/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4565 - accuracy: 0.7841 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 669/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.4572 - accuracy: 0.7902 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 670/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4561 - accuracy: 0.7841 - val_loss: 0.5213 - val_accuracy: 0.7398\n",
            "Epoch 671/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4556 - accuracy: 0.7882 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 672/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4561 - accuracy: 0.7862 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 673/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4557 - accuracy: 0.7800 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 674/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4557 - accuracy: 0.7862 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 675/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4554 - accuracy: 0.7923 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 676/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4554 - accuracy: 0.7862 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 677/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4557 - accuracy: 0.7862 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 678/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4556 - accuracy: 0.7862 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 679/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4562 - accuracy: 0.7841 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 680/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4550 - accuracy: 0.7862 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 681/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4553 - accuracy: 0.7902 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 682/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4548 - accuracy: 0.7841 - val_loss: 0.5210 - val_accuracy: 0.7480\n",
            "Epoch 683/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4552 - accuracy: 0.7821 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 684/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4548 - accuracy: 0.7821 - val_loss: 0.5212 - val_accuracy: 0.7561\n",
            "Epoch 685/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4555 - accuracy: 0.7841 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 686/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4549 - accuracy: 0.7862 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 687/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4554 - accuracy: 0.7821 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 688/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4545 - accuracy: 0.7902 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 689/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4547 - accuracy: 0.7902 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 690/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4546 - accuracy: 0.7882 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 691/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4542 - accuracy: 0.7902 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 692/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4551 - accuracy: 0.7862 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 693/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4547 - accuracy: 0.7841 - val_loss: 0.5218 - val_accuracy: 0.7561\n",
            "Epoch 694/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4546 - accuracy: 0.7841 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 695/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4543 - accuracy: 0.7841 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 696/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4539 - accuracy: 0.7882 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 697/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4542 - accuracy: 0.7841 - val_loss: 0.5213 - val_accuracy: 0.7642\n",
            "Epoch 698/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 699/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4546 - accuracy: 0.7882 - val_loss: 0.5212 - val_accuracy: 0.7480\n",
            "Epoch 700/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4547 - accuracy: 0.7902 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 701/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4546 - accuracy: 0.7923 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 702/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4540 - accuracy: 0.7841 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 703/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4534 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
            "Epoch 704/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4537 - accuracy: 0.7862 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 705/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4535 - accuracy: 0.7923 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 706/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4538 - accuracy: 0.7841 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 707/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4534 - accuracy: 0.7902 - val_loss: 0.5216 - val_accuracy: 0.7561\n",
            "Epoch 708/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4534 - accuracy: 0.7862 - val_loss: 0.5217 - val_accuracy: 0.7561\n",
            "Epoch 709/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.4538 - accuracy: 0.7841 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 710/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4535 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 711/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4539 - accuracy: 0.7862 - val_loss: 0.5216 - val_accuracy: 0.7480\n",
            "Epoch 712/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4531 - accuracy: 0.7902 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 713/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4534 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 714/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4532 - accuracy: 0.7902 - val_loss: 0.5214 - val_accuracy: 0.7480\n",
            "Epoch 715/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4527 - accuracy: 0.7902 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 716/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4530 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 717/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4532 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 718/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4538 - accuracy: 0.7902 - val_loss: 0.5213 - val_accuracy: 0.7642\n",
            "Epoch 719/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4529 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 720/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4523 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 721/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4536 - accuracy: 0.7862 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 722/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4527 - accuracy: 0.7862 - val_loss: 0.5212 - val_accuracy: 0.7642\n",
            "Epoch 723/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4523 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7561\n",
            "Epoch 724/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4524 - accuracy: 0.7841 - val_loss: 0.5212 - val_accuracy: 0.7642\n",
            "Epoch 725/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4526 - accuracy: 0.7923 - val_loss: 0.5212 - val_accuracy: 0.7642\n",
            "Epoch 726/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4530 - accuracy: 0.7841 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 727/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4530 - accuracy: 0.7862 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 728/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4535 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7642\n",
            "Epoch 729/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4522 - accuracy: 0.7923 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 730/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4524 - accuracy: 0.7923 - val_loss: 0.5212 - val_accuracy: 0.7642\n",
            "Epoch 731/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4521 - accuracy: 0.7882 - val_loss: 0.5212 - val_accuracy: 0.7642\n",
            "Epoch 732/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4525 - accuracy: 0.7902 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 733/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4516 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7642\n",
            "Epoch 734/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4518 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 735/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4524 - accuracy: 0.7841 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 736/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4521 - accuracy: 0.7841 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 737/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4515 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7642\n",
            "Epoch 738/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4520 - accuracy: 0.7902 - val_loss: 0.5213 - val_accuracy: 0.7642\n",
            "Epoch 739/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4516 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7642\n",
            "Epoch 740/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4533 - accuracy: 0.7862 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 741/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4519 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.7642\n",
            "Epoch 742/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4526 - accuracy: 0.7862 - val_loss: 0.5213 - val_accuracy: 0.7642\n",
            "Epoch 743/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4515 - accuracy: 0.7882 - val_loss: 0.5212 - val_accuracy: 0.7642\n",
            "Epoch 744/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4516 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 745/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4513 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7561\n",
            "Epoch 746/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4510 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.7642\n",
            "Epoch 747/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4517 - accuracy: 0.7862 - val_loss: 0.5213 - val_accuracy: 0.7642\n",
            "Epoch 748/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4518 - accuracy: 0.7841 - val_loss: 0.5213 - val_accuracy: 0.7642\n",
            "Epoch 749/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4511 - accuracy: 0.7902 - val_loss: 0.5214 - val_accuracy: 0.7642\n",
            "Epoch 750/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4512 - accuracy: 0.7862 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 751/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4512 - accuracy: 0.7902 - val_loss: 0.5214 - val_accuracy: 0.7642\n",
            "Epoch 752/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4508 - accuracy: 0.7862 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 753/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 754/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4510 - accuracy: 0.7841 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 755/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4515 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 756/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4510 - accuracy: 0.7862 - val_loss: 0.5217 - val_accuracy: 0.7724\n",
            "Epoch 757/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4508 - accuracy: 0.7841 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 758/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4511 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7561\n",
            "Epoch 759/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4510 - accuracy: 0.7862 - val_loss: 0.5219 - val_accuracy: 0.7724\n",
            "Epoch 760/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4515 - accuracy: 0.7902 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 761/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.5218 - val_accuracy: 0.7561\n",
            "Epoch 762/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4512 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7642\n",
            "Epoch 763/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4506 - accuracy: 0.7923 - val_loss: 0.5216 - val_accuracy: 0.7642\n",
            "Epoch 764/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4508 - accuracy: 0.7862 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 765/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4507 - accuracy: 0.7841 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 766/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4498 - accuracy: 0.7923 - val_loss: 0.5216 - val_accuracy: 0.7642\n",
            "Epoch 767/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4500 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7642\n",
            "Epoch 768/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4502 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7642\n",
            "Epoch 769/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4500 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 770/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4502 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7642\n",
            "Epoch 771/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4498 - accuracy: 0.7841 - val_loss: 0.5219 - val_accuracy: 0.7561\n",
            "Epoch 772/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7642\n",
            "Epoch 773/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4498 - accuracy: 0.7862 - val_loss: 0.5216 - val_accuracy: 0.7642\n",
            "Epoch 774/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4500 - accuracy: 0.7862 - val_loss: 0.5219 - val_accuracy: 0.7724\n",
            "Epoch 775/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4500 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7642\n",
            "Epoch 776/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4499 - accuracy: 0.7862 - val_loss: 0.5219 - val_accuracy: 0.7724\n",
            "Epoch 777/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4498 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7642\n",
            "Epoch 778/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4499 - accuracy: 0.7943 - val_loss: 0.5218 - val_accuracy: 0.7642\n",
            "Epoch 779/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4498 - accuracy: 0.7862 - val_loss: 0.5218 - val_accuracy: 0.7642\n",
            "Epoch 780/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4501 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7642\n",
            "Epoch 781/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4500 - accuracy: 0.7862 - val_loss: 0.5219 - val_accuracy: 0.7642\n",
            "Epoch 782/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4493 - accuracy: 0.7902 - val_loss: 0.5218 - val_accuracy: 0.7642\n",
            "Epoch 783/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4496 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7642\n",
            "Epoch 784/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4505 - accuracy: 0.7862 - val_loss: 0.5216 - val_accuracy: 0.7642\n",
            "Epoch 785/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4494 - accuracy: 0.7902 - val_loss: 0.5217 - val_accuracy: 0.7642\n",
            "Epoch 786/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4491 - accuracy: 0.7862 - val_loss: 0.5216 - val_accuracy: 0.7724\n",
            "Epoch 787/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4504 - accuracy: 0.7902 - val_loss: 0.5217 - val_accuracy: 0.7642\n",
            "Epoch 788/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4491 - accuracy: 0.7862 - val_loss: 0.5217 - val_accuracy: 0.7642\n",
            "Epoch 789/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4493 - accuracy: 0.7862 - val_loss: 0.5215 - val_accuracy: 0.7724\n",
            "Epoch 790/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4498 - accuracy: 0.7902 - val_loss: 0.5217 - val_accuracy: 0.7724\n",
            "Epoch 791/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4494 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7724\n",
            "Epoch 792/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4490 - accuracy: 0.7841 - val_loss: 0.5217 - val_accuracy: 0.7724\n",
            "Epoch 793/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4493 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 794/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4488 - accuracy: 0.7841 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 795/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4486 - accuracy: 0.7902 - val_loss: 0.5215 - val_accuracy: 0.7642\n",
            "Epoch 796/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4485 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7642\n",
            "Epoch 797/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4491 - accuracy: 0.7862 - val_loss: 0.5217 - val_accuracy: 0.7724\n",
            "Epoch 798/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4500 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7724\n",
            "Epoch 799/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4496 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7724\n",
            "Epoch 800/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7724\n",
            "Epoch 801/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4487 - accuracy: 0.7841 - val_loss: 0.5216 - val_accuracy: 0.7724\n",
            "Epoch 802/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4485 - accuracy: 0.7862 - val_loss: 0.5216 - val_accuracy: 0.7724\n",
            "Epoch 803/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4484 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7724\n",
            "Epoch 804/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4480 - accuracy: 0.7882 - val_loss: 0.5218 - val_accuracy: 0.7805\n",
            "Epoch 805/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4484 - accuracy: 0.7862 - val_loss: 0.5215 - val_accuracy: 0.7805\n",
            "Epoch 806/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4484 - accuracy: 0.7902 - val_loss: 0.5215 - val_accuracy: 0.7724\n",
            "Epoch 807/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4484 - accuracy: 0.7882 - val_loss: 0.5214 - val_accuracy: 0.7805\n",
            "Epoch 808/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4479 - accuracy: 0.7902 - val_loss: 0.5214 - val_accuracy: 0.7805\n",
            "Epoch 809/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7724\n",
            "Epoch 810/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4483 - accuracy: 0.7902 - val_loss: 0.5218 - val_accuracy: 0.7805\n",
            "Epoch 811/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4480 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.7805\n",
            "Epoch 812/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4480 - accuracy: 0.7862 - val_loss: 0.5213 - val_accuracy: 0.7805\n",
            "Epoch 813/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4478 - accuracy: 0.7882 - val_loss: 0.5214 - val_accuracy: 0.7805\n",
            "Epoch 814/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4480 - accuracy: 0.7902 - val_loss: 0.5217 - val_accuracy: 0.7724\n",
            "Epoch 815/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4494 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.7724\n",
            "Epoch 816/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4481 - accuracy: 0.7882 - val_loss: 0.5214 - val_accuracy: 0.7724\n",
            "Epoch 817/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4479 - accuracy: 0.7902 - val_loss: 0.5218 - val_accuracy: 0.7805\n",
            "Epoch 818/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4476 - accuracy: 0.7902 - val_loss: 0.5213 - val_accuracy: 0.7805\n",
            "Epoch 819/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4476 - accuracy: 0.7882 - val_loss: 0.5212 - val_accuracy: 0.7805\n",
            "Epoch 820/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4479 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7805\n",
            "Epoch 821/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4478 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7805\n",
            "Epoch 822/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4472 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7805\n",
            "Epoch 823/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4474 - accuracy: 0.7841 - val_loss: 0.5213 - val_accuracy: 0.7805\n",
            "Epoch 824/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4475 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7805\n",
            "Epoch 825/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4481 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.7724\n",
            "Epoch 826/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4469 - accuracy: 0.7882 - val_loss: 0.5214 - val_accuracy: 0.7805\n",
            "Epoch 827/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7805\n",
            "Epoch 828/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4474 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.7805\n",
            "Epoch 829/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4472 - accuracy: 0.7882 - val_loss: 0.5214 - val_accuracy: 0.7805\n",
            "Epoch 830/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4478 - accuracy: 0.7841 - val_loss: 0.5213 - val_accuracy: 0.7724\n",
            "Epoch 831/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4474 - accuracy: 0.7800 - val_loss: 0.5213 - val_accuracy: 0.7805\n",
            "Epoch 832/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4473 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.7805\n",
            "Epoch 833/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4467 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7724\n",
            "Epoch 834/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4471 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.7805\n",
            "Epoch 835/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4479 - accuracy: 0.7882 - val_loss: 0.5214 - val_accuracy: 0.7805\n",
            "Epoch 836/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4477 - accuracy: 0.7862 - val_loss: 0.5213 - val_accuracy: 0.7805\n",
            "Epoch 837/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4484 - accuracy: 0.7902 - val_loss: 0.5213 - val_accuracy: 0.7805\n",
            "Epoch 838/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4466 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.7805\n",
            "Epoch 839/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4473 - accuracy: 0.7862 - val_loss: 0.5215 - val_accuracy: 0.7805\n",
            "Epoch 840/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4464 - accuracy: 0.7841 - val_loss: 0.5217 - val_accuracy: 0.7724\n",
            "Epoch 841/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4471 - accuracy: 0.7862 - val_loss: 0.5215 - val_accuracy: 0.7805\n",
            "Epoch 842/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4466 - accuracy: 0.7862 - val_loss: 0.5217 - val_accuracy: 0.7724\n",
            "Epoch 843/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4464 - accuracy: 0.7862 - val_loss: 0.5217 - val_accuracy: 0.7724\n",
            "Epoch 844/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4464 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7805\n",
            "Epoch 845/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4471 - accuracy: 0.7862 - val_loss: 0.5218 - val_accuracy: 0.7805\n",
            "Epoch 846/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4469 - accuracy: 0.7862 - val_loss: 0.5215 - val_accuracy: 0.7724\n",
            "Epoch 847/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4471 - accuracy: 0.7862 - val_loss: 0.5216 - val_accuracy: 0.7805\n",
            "Epoch 848/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4469 - accuracy: 0.7862 - val_loss: 0.5216 - val_accuracy: 0.7805\n",
            "Epoch 849/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4463 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7805\n",
            "Epoch 850/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4459 - accuracy: 0.7902 - val_loss: 0.5217 - val_accuracy: 0.7805\n",
            "Epoch 851/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4463 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7805\n",
            "Epoch 852/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.5219 - val_accuracy: 0.7724\n",
            "Epoch 853/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4459 - accuracy: 0.7862 - val_loss: 0.5219 - val_accuracy: 0.7724\n",
            "Epoch 854/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4463 - accuracy: 0.7841 - val_loss: 0.5219 - val_accuracy: 0.7724\n",
            "Epoch 855/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.5218 - val_accuracy: 0.7805\n",
            "Epoch 856/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4463 - accuracy: 0.7800 - val_loss: 0.5226 - val_accuracy: 0.7561\n",
            "Epoch 857/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4482 - accuracy: 0.7882 - val_loss: 0.5220 - val_accuracy: 0.7724\n",
            "Epoch 858/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.5218 - val_accuracy: 0.7805\n",
            "Epoch 859/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4462 - accuracy: 0.7862 - val_loss: 0.5219 - val_accuracy: 0.7805\n",
            "Epoch 860/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4455 - accuracy: 0.7862 - val_loss: 0.5220 - val_accuracy: 0.7724\n",
            "Epoch 861/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.5219 - val_accuracy: 0.7805\n",
            "Epoch 862/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.5219 - val_accuracy: 0.7805\n",
            "Epoch 863/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4457 - accuracy: 0.7862 - val_loss: 0.5222 - val_accuracy: 0.7805\n",
            "Epoch 864/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4474 - accuracy: 0.7882 - val_loss: 0.5219 - val_accuracy: 0.7805\n",
            "Epoch 865/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4467 - accuracy: 0.7821 - val_loss: 0.5221 - val_accuracy: 0.7724\n",
            "Epoch 866/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.5220 - val_accuracy: 0.7805\n",
            "Epoch 867/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4460 - accuracy: 0.7841 - val_loss: 0.5223 - val_accuracy: 0.7724\n",
            "Epoch 868/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4463 - accuracy: 0.7862 - val_loss: 0.5220 - val_accuracy: 0.7805\n",
            "Epoch 869/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4468 - accuracy: 0.7862 - val_loss: 0.5221 - val_accuracy: 0.7805\n",
            "Epoch 870/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4460 - accuracy: 0.7821 - val_loss: 0.5223 - val_accuracy: 0.7724\n",
            "Epoch 871/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4453 - accuracy: 0.7841 - val_loss: 0.5223 - val_accuracy: 0.7724\n",
            "Epoch 872/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.5221 - val_accuracy: 0.7805\n",
            "Epoch 873/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.5222 - val_accuracy: 0.7805\n",
            "Epoch 874/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4461 - accuracy: 0.7862 - val_loss: 0.5224 - val_accuracy: 0.7724\n",
            "Epoch 875/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4455 - accuracy: 0.7862 - val_loss: 0.5222 - val_accuracy: 0.7805\n",
            "Epoch 876/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4451 - accuracy: 0.7862 - val_loss: 0.5224 - val_accuracy: 0.7724\n",
            "Epoch 877/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4451 - accuracy: 0.7902 - val_loss: 0.5224 - val_accuracy: 0.7805\n",
            "Epoch 878/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4452 - accuracy: 0.7902 - val_loss: 0.5224 - val_accuracy: 0.7805\n",
            "Epoch 879/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4453 - accuracy: 0.7902 - val_loss: 0.5224 - val_accuracy: 0.7805\n",
            "Epoch 880/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.5226 - val_accuracy: 0.7724\n",
            "Epoch 881/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4449 - accuracy: 0.7862 - val_loss: 0.5224 - val_accuracy: 0.7805\n",
            "Epoch 882/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4467 - accuracy: 0.7862 - val_loss: 0.5224 - val_accuracy: 0.7805\n",
            "Epoch 883/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4453 - accuracy: 0.7862 - val_loss: 0.5224 - val_accuracy: 0.7805\n",
            "Epoch 884/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.5225 - val_accuracy: 0.7805\n",
            "Epoch 885/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4459 - accuracy: 0.7902 - val_loss: 0.5225 - val_accuracy: 0.7805\n",
            "Epoch 886/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4446 - accuracy: 0.7862 - val_loss: 0.5226 - val_accuracy: 0.7724\n",
            "Epoch 887/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.5225 - val_accuracy: 0.7805\n",
            "Epoch 888/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4449 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7642\n",
            "Epoch 889/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.5230 - val_accuracy: 0.7561\n",
            "Epoch 890/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4455 - accuracy: 0.7841 - val_loss: 0.5225 - val_accuracy: 0.7805\n",
            "Epoch 891/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4443 - accuracy: 0.7862 - val_loss: 0.5227 - val_accuracy: 0.7724\n",
            "Epoch 892/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.5225 - val_accuracy: 0.7805\n",
            "Epoch 893/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4448 - accuracy: 0.7862 - val_loss: 0.5226 - val_accuracy: 0.7805\n",
            "Epoch 894/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.5226 - val_accuracy: 0.7724\n",
            "Epoch 895/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4465 - accuracy: 0.7862 - val_loss: 0.5230 - val_accuracy: 0.7642\n",
            "Epoch 896/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4454 - accuracy: 0.7902 - val_loss: 0.5234 - val_accuracy: 0.7561\n",
            "Epoch 897/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4450 - accuracy: 0.7902 - val_loss: 0.5228 - val_accuracy: 0.7724\n",
            "Epoch 898/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4446 - accuracy: 0.7841 - val_loss: 0.5226 - val_accuracy: 0.7805\n",
            "Epoch 899/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4444 - accuracy: 0.7862 - val_loss: 0.5227 - val_accuracy: 0.7805\n",
            "Epoch 900/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4446 - accuracy: 0.7902 - val_loss: 0.5227 - val_accuracy: 0.7805\n",
            "Epoch 901/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4454 - accuracy: 0.7862 - val_loss: 0.5229 - val_accuracy: 0.7805\n",
            "Epoch 902/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4455 - accuracy: 0.7902 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 903/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4452 - accuracy: 0.7943 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 904/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4453 - accuracy: 0.7841 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 905/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4442 - accuracy: 0.7862 - val_loss: 0.5228 - val_accuracy: 0.7724\n",
            "Epoch 906/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 907/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 908/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4448 - accuracy: 0.7841 - val_loss: 0.5229 - val_accuracy: 0.7724\n",
            "Epoch 909/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7724\n",
            "Epoch 910/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4440 - accuracy: 0.7862 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 911/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4439 - accuracy: 0.7902 - val_loss: 0.5229 - val_accuracy: 0.7724\n",
            "Epoch 912/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 913/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4445 - accuracy: 0.7902 - val_loss: 0.5229 - val_accuracy: 0.7805\n",
            "Epoch 914/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4454 - accuracy: 0.7862 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 915/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4450 - accuracy: 0.7902 - val_loss: 0.5230 - val_accuracy: 0.7724\n",
            "Epoch 916/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.5232 - val_accuracy: 0.7724\n",
            "Epoch 917/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.5233 - val_accuracy: 0.7724\n",
            "Epoch 918/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.5231 - val_accuracy: 0.7724\n",
            "Epoch 919/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7805\n",
            "Epoch 920/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7805\n",
            "Epoch 921/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7805\n",
            "Epoch 922/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4438 - accuracy: 0.7862 - val_loss: 0.5229 - val_accuracy: 0.7805\n",
            "Epoch 923/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4443 - accuracy: 0.7902 - val_loss: 0.5229 - val_accuracy: 0.7805\n",
            "Epoch 924/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4436 - accuracy: 0.7902 - val_loss: 0.5236 - val_accuracy: 0.7561\n",
            "Epoch 925/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 926/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4451 - accuracy: 0.7862 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 927/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4447 - accuracy: 0.7841 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 928/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4446 - accuracy: 0.7902 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 929/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4438 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7724\n",
            "Epoch 930/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4439 - accuracy: 0.7902 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 931/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4445 - accuracy: 0.7902 - val_loss: 0.5229 - val_accuracy: 0.7724\n",
            "Epoch 932/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4442 - accuracy: 0.7902 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 933/1000\n",
            "491/491 [==============================] - 0s 49us/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7805\n",
            "Epoch 934/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4438 - accuracy: 0.7862 - val_loss: 0.5227 - val_accuracy: 0.7805\n",
            "Epoch 935/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4437 - accuracy: 0.7963 - val_loss: 0.5229 - val_accuracy: 0.7724\n",
            "Epoch 936/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4447 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 937/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 938/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4433 - accuracy: 0.7943 - val_loss: 0.5229 - val_accuracy: 0.7724\n",
            "Epoch 939/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4438 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 940/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4434 - accuracy: 0.7923 - val_loss: 0.5229 - val_accuracy: 0.7805\n",
            "Epoch 941/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4441 - accuracy: 0.7902 - val_loss: 0.5231 - val_accuracy: 0.7724\n",
            "Epoch 942/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4433 - accuracy: 0.7902 - val_loss: 0.5230 - val_accuracy: 0.7805\n",
            "Epoch 943/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4443 - accuracy: 0.7923 - val_loss: 0.5229 - val_accuracy: 0.7805\n",
            "Epoch 944/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4440 - accuracy: 0.7841 - val_loss: 0.5231 - val_accuracy: 0.7642\n",
            "Epoch 945/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4436 - accuracy: 0.7841 - val_loss: 0.5231 - val_accuracy: 0.7805\n",
            "Epoch 946/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4435 - accuracy: 0.7902 - val_loss: 0.5231 - val_accuracy: 0.7805\n",
            "Epoch 947/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4432 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7724\n",
            "Epoch 948/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4437 - accuracy: 0.7862 - val_loss: 0.5231 - val_accuracy: 0.7805\n",
            "Epoch 949/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4435 - accuracy: 0.7902 - val_loss: 0.5234 - val_accuracy: 0.7724\n",
            "Epoch 950/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4430 - accuracy: 0.7902 - val_loss: 0.5232 - val_accuracy: 0.7642\n",
            "Epoch 951/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4430 - accuracy: 0.7902 - val_loss: 0.5231 - val_accuracy: 0.7805\n",
            "Epoch 952/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4432 - accuracy: 0.7902 - val_loss: 0.5231 - val_accuracy: 0.7805\n",
            "Epoch 953/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7805\n",
            "Epoch 954/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4434 - accuracy: 0.7862 - val_loss: 0.5231 - val_accuracy: 0.7805\n",
            "Epoch 955/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4438 - accuracy: 0.7902 - val_loss: 0.5231 - val_accuracy: 0.7805\n",
            "Epoch 956/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4426 - accuracy: 0.7923 - val_loss: 0.5231 - val_accuracy: 0.7805\n",
            "Epoch 957/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4430 - accuracy: 0.7943 - val_loss: 0.5236 - val_accuracy: 0.7724\n",
            "Epoch 958/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4426 - accuracy: 0.7882 - val_loss: 0.5231 - val_accuracy: 0.7805\n",
            "Epoch 959/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4431 - accuracy: 0.7963 - val_loss: 0.5232 - val_accuracy: 0.7805\n",
            "Epoch 960/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4433 - accuracy: 0.7862 - val_loss: 0.5240 - val_accuracy: 0.7642\n",
            "Epoch 961/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4432 - accuracy: 0.7862 - val_loss: 0.5234 - val_accuracy: 0.7724\n",
            "Epoch 962/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4438 - accuracy: 0.7902 - val_loss: 0.5239 - val_accuracy: 0.7642\n",
            "Epoch 963/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4435 - accuracy: 0.7902 - val_loss: 0.5237 - val_accuracy: 0.7724\n",
            "Epoch 964/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4434 - accuracy: 0.7902 - val_loss: 0.5233 - val_accuracy: 0.7805\n",
            "Epoch 965/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.4427 - accuracy: 0.7923 - val_loss: 0.5233 - val_accuracy: 0.7805\n",
            "Epoch 966/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4427 - accuracy: 0.7923 - val_loss: 0.5234 - val_accuracy: 0.7805\n",
            "Epoch 967/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7724\n",
            "Epoch 968/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4431 - accuracy: 0.7902 - val_loss: 0.5237 - val_accuracy: 0.7724\n",
            "Epoch 969/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.5234 - val_accuracy: 0.7805\n",
            "Epoch 970/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4421 - accuracy: 0.7963 - val_loss: 0.5240 - val_accuracy: 0.7642\n",
            "Epoch 971/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4433 - accuracy: 0.7862 - val_loss: 0.5239 - val_accuracy: 0.7724\n",
            "Epoch 972/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4427 - accuracy: 0.7923 - val_loss: 0.5239 - val_accuracy: 0.7724\n",
            "Epoch 973/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4434 - accuracy: 0.7902 - val_loss: 0.5235 - val_accuracy: 0.7805\n",
            "Epoch 974/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4425 - accuracy: 0.7943 - val_loss: 0.5236 - val_accuracy: 0.7805\n",
            "Epoch 975/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.5238 - val_accuracy: 0.7805\n",
            "Epoch 976/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7805\n",
            "Epoch 977/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7805\n",
            "Epoch 978/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4421 - accuracy: 0.7862 - val_loss: 0.5240 - val_accuracy: 0.7642\n",
            "Epoch 979/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4425 - accuracy: 0.7862 - val_loss: 0.5236 - val_accuracy: 0.7805\n",
            "Epoch 980/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4436 - accuracy: 0.7841 - val_loss: 0.5244 - val_accuracy: 0.7561\n",
            "Epoch 981/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4426 - accuracy: 0.7841 - val_loss: 0.5238 - val_accuracy: 0.7805\n",
            "Epoch 982/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4435 - accuracy: 0.7862 - val_loss: 0.5236 - val_accuracy: 0.7805\n",
            "Epoch 983/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4424 - accuracy: 0.7902 - val_loss: 0.5236 - val_accuracy: 0.7805\n",
            "Epoch 984/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4422 - accuracy: 0.7963 - val_loss: 0.5236 - val_accuracy: 0.7805\n",
            "Epoch 985/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4425 - accuracy: 0.7862 - val_loss: 0.5235 - val_accuracy: 0.7805\n",
            "Epoch 986/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4426 - accuracy: 0.7882 - val_loss: 0.5236 - val_accuracy: 0.7805\n",
            "Epoch 987/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4424 - accuracy: 0.7923 - val_loss: 0.5237 - val_accuracy: 0.7805\n",
            "Epoch 988/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4441 - accuracy: 0.7821 - val_loss: 0.5238 - val_accuracy: 0.7805\n",
            "Epoch 989/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4428 - accuracy: 0.7902 - val_loss: 0.5246 - val_accuracy: 0.7561\n",
            "Epoch 990/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4422 - accuracy: 0.7841 - val_loss: 0.5237 - val_accuracy: 0.7805\n",
            "Epoch 991/1000\n",
            "491/491 [==============================] - 0s 60us/step - loss: 0.4432 - accuracy: 0.7882 - val_loss: 0.5237 - val_accuracy: 0.7805\n",
            "Epoch 992/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5238 - val_accuracy: 0.7805\n",
            "Epoch 993/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4420 - accuracy: 0.7943 - val_loss: 0.5241 - val_accuracy: 0.7805\n",
            "Epoch 994/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4422 - accuracy: 0.7902 - val_loss: 0.5247 - val_accuracy: 0.7561\n",
            "Epoch 995/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4422 - accuracy: 0.7923 - val_loss: 0.5251 - val_accuracy: 0.7561\n",
            "Epoch 996/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4420 - accuracy: 0.7862 - val_loss: 0.5239 - val_accuracy: 0.7805\n",
            "Epoch 997/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4419 - accuracy: 0.7943 - val_loss: 0.5240 - val_accuracy: 0.7805\n",
            "Epoch 998/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4418 - accuracy: 0.7923 - val_loss: 0.5240 - val_accuracy: 0.7805\n",
            "Epoch 999/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4419 - accuracy: 0.7882 - val_loss: 0.5240 - val_accuracy: 0.7805\n",
            "Epoch 1000/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4433 - accuracy: 0.7923 - val_loss: 0.5240 - val_accuracy: 0.7805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVAZEtX2JA_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ac937461-63d7-4000-fb22-78833c495101"
      },
      "source": [
        "#visualize the training loss and validation loss to see if the model is overfitting\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Val'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKKr2FdGJxYG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c1220a4a-663b-45d3-a463-fd7f0acc3f80"
      },
      "source": [
        "#visualize the training accuracy and validation accuracy to see if the model is overfitting\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model Acc')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Val'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGL0liXcKFul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "40589607-34f7-41da-c835-3e62b3127c89"
      },
      "source": [
        "#make a prediction and print acctual values\n",
        "prediction = model.predict(x_test)\n",
        "prediction = [1 if y>=0.5 else 0 for y in prediction]\n",
        "print(prediction)\n",
        "print(y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
            "[0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnhXJ4vLIem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a7560df6-2954-466f-f93b-85f0ec35d120"
      },
      "source": [
        "#evaluate the model on training dataset\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "pred = model.predict(x_train)\n",
        "pred = [1 if y>=0.5 else 0 for y in pred]\n",
        "print(classification_report(y_train, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_train, pred))\n",
        "print()\n",
        "print('Accuracy \\n', accuracy_score(y_train, pred))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.89      0.85       398\n",
            "         1.0       0.75      0.61      0.67       216\n",
            "\n",
            "    accuracy                           0.79       614\n",
            "   macro avg       0.78      0.75      0.76       614\n",
            "weighted avg       0.79      0.79      0.79       614\n",
            "\n",
            "Confusion Matrix: \n",
            " [[354  44]\n",
            " [ 84 132]]\n",
            "\n",
            "Accuracy \n",
            " 0.7915309446254072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x09V8ltMJ1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ba800850-4e83-49de-cc27-4ca8a021320b",
        "id": "WgRAVqljMMgv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "#evaluate the model on test dataset\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "pred = model.predict(x_test)\n",
        "pred = [1 if y>=0.5 else 0 for y in pred]\n",
        "print(classification_report(y_test, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, pred))\n",
        "print()\n",
        "print('Accuracy \\n', accuracy_score(y_test, pred))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.81      0.82       102\n",
            "         1.0       0.64      0.65      0.65        52\n",
            "\n",
            "    accuracy                           0.76       154\n",
            "   macro avg       0.73      0.73      0.73       154\n",
            "weighted avg       0.76      0.76      0.76       154\n",
            "\n",
            "Confusion Matrix: \n",
            " [[83 19]\n",
            " [18 34]]\n",
            "\n",
            "Accuracy \n",
            " 0.7597402597402597\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}